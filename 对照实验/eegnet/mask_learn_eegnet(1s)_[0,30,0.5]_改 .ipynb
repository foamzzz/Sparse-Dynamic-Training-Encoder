{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from metabci.brainda.algorithms.deep_learning import EEGNet_Sparse\n",
    "from metabci.brainda.algorithms.utils.model_selection import (\n",
    "    set_random_seeds,\n",
    "    generate_kfold_indices, match_kfold_indices)\n",
    "from metabci.brainda.datasets import Wang2016, BETA\n",
    "# 三个SSVEP Datasets：Nakanishi2015、Wang2016、BETA\n",
    "from metabci.brainda.paradigms import SSVEP\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------ssssss, /upload/yijun/S1.mat.7z\n",
      "--------ssssss, /upload/yijun/S2.mat.7z\n",
      "--------ssssss, /upload/yijun/S3.mat.7z\n",
      "--------ssssss, /upload/yijun/S4.mat.7z\n",
      "--------ssssss, /upload/yijun/S5.mat.7z\n",
      "--------ssssss, /upload/yijun/S6.mat.7z\n",
      "--------ssssss, /upload/yijun/S7.mat.7z\n",
      "--------ssssss, /upload/yijun/S8.mat.7z\n",
      "--------ssssss, /upload/yijun/S9.mat.7z\n",
      "--------ssssss, /upload/yijun/S10.mat.7z\n",
      "--------ssssss, /upload/yijun/S11.mat.7z\n",
      "--------ssssss, /upload/yijun/S12.mat.7z\n",
      "--------ssssss, /upload/yijun/S13.mat.7z\n",
      "--------ssssss, /upload/yijun/S14.mat.7z\n",
      "--------ssssss, /upload/yijun/S15.mat.7z\n",
      "--------ssssss, /upload/yijun/S16.mat.7z\n",
      "--------ssssss, /upload/yijun/S17.mat.7z\n",
      "--------ssssss, /upload/yijun/S18.mat.7z\n",
      "--------ssssss, /upload/yijun/S19.mat.7z\n",
      "--------ssssss, /upload/yijun/S20.mat.7z\n",
      "--------ssssss, /upload/yijun/S1.mat.7z\n",
      "--------ssssss, /upload/yijun/S2.mat.7z\n",
      "--------ssssss, /upload/yijun/S3.mat.7z\n",
      "--------ssssss, /upload/yijun/S4.mat.7z\n",
      "--------ssssss, /upload/yijun/S5.mat.7z\n",
      "--------ssssss, /upload/yijun/S6.mat.7z\n",
      "--------ssssss, /upload/yijun/S7.mat.7z\n",
      "--------ssssss, /upload/yijun/S8.mat.7z\n",
      "--------ssssss, /upload/yijun/S9.mat.7z\n",
      "--------ssssss, /upload/yijun/S10.mat.7z\n",
      "--------ssssss, /upload/yijun/S11.mat.7z\n",
      "--------ssssss, /upload/yijun/S12.mat.7z\n",
      "--------ssssss, /upload/yijun/S13.mat.7z\n",
      "--------ssssss, /upload/yijun/S14.mat.7z\n",
      "--------ssssss, /upload/yijun/S15.mat.7z\n",
      "--------ssssss, /upload/yijun/S16.mat.7z\n",
      "--------ssssss, /upload/yijun/S17.mat.7z\n",
      "--------ssssss, /upload/yijun/S18.mat.7z\n",
      "--------ssssss, /upload/yijun/S19.mat.7z\n",
      "--------ssssss, /upload/yijun/S20.mat.7z\n"
     ]
    }
   ],
   "source": [
    "#**************************************************\n",
    "# Benchmark数据集读取处理\n",
    "#**************************************************\n",
    "Bench_dataset = Wang2016()\n",
    "subject_list = list(range(1, 21))  # 被试编号从1到20\n",
    "for s in subject_list:\n",
    "    Bench_dataset.data_path(subject=s, path=\"E:\\\\MetaBCI-master\\\\mne_data\")  # 依次为每个被试设置路径\n",
    "events = Bench_dataset.events.keys()\n",
    "freq_list = [str(Bench_dataset.get_freq(event)) for event in events]  # 获得所有刺激的频率\n",
    "freq_map = {i: freq for i, freq in enumerate(freq_list)}  # 标签到频率的映射\n",
    "\n",
    "Bench_subjects = list(range(1, 21))  # 使用S1–S20被试进行训练\n",
    "Bench_paradigm = SSVEP(\n",
    "    channels=['POZ', 'PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'O1', 'OZ', 'O2'],  # 选择电极通道\n",
    "    intervals=[(0.14, 1.14)],  # 分析时间窗最长-0.5-5.5s ,0.0是刺激开始\n",
    "    events=freq_list,  # 选择所有刺激频率\n",
    "    srate=250  # 采样率\n",
    ")\n",
    "\n",
    "# add 5-90Hz bandpass filter in raw hook\n",
    "# 对原始EEG信号做5-90Hz带通滤波。\n",
    "def raw_hook(raw, caches):\n",
    "    raw.filter(5, 90, l_trans_bandwidth=2, h_trans_bandwidth=5, phase='zero-double')\n",
    "    caches['raw_stage'] = caches.get('raw_stage', -1) + 1\n",
    "    return raw, caches\n",
    "\n",
    "Bench_paradigm.register_raw_hook(raw_hook)\n",
    "\n",
    "\n",
    "\n",
    "# 获取微调数据\n",
    "X_Bench, y_Bench, meta_Bench = Bench_paradigm.get_data(\n",
    "    Bench_dataset,\n",
    "    subjects=Bench_subjects,\n",
    "    return_concat=True,\n",
    "    n_jobs=None,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(4800, 9, 250)\n",
      "train_ind数量: 4000, validate_ind数量: 800, test_ind数量: 800\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      lr     dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  ------  ------\n",
      "      1       \u001b[36m0.0248\u001b[0m        \u001b[32m3.7725\u001b[0m       \u001b[35m0.0312\u001b[0m        \u001b[31m3.6887\u001b[0m     +  0.0010  1.5809\n",
      "      2       \u001b[36m0.0295\u001b[0m        \u001b[32m3.7252\u001b[0m       \u001b[35m0.0475\u001b[0m        \u001b[31m3.6781\u001b[0m     +  0.0010  1.3899\n",
      "      3       \u001b[36m0.0372\u001b[0m        \u001b[32m3.6942\u001b[0m       \u001b[35m0.0625\u001b[0m        \u001b[31m3.6620\u001b[0m     +  0.0010  1.4074\n",
      "      4       \u001b[36m0.0393\u001b[0m        \u001b[32m3.6825\u001b[0m       \u001b[35m0.0788\u001b[0m        \u001b[31m3.6408\u001b[0m     +  0.0010  1.3896\n",
      "      5       \u001b[36m0.0530\u001b[0m        \u001b[32m3.6531\u001b[0m       \u001b[35m0.0950\u001b[0m        \u001b[31m3.6145\u001b[0m     +  0.0010  1.3964\n",
      "      6       \u001b[36m0.0650\u001b[0m        \u001b[32m3.6254\u001b[0m       \u001b[35m0.1075\u001b[0m        \u001b[31m3.5805\u001b[0m     +  0.0010  1.4158\n",
      "      7       \u001b[36m0.0813\u001b[0m        \u001b[32m3.5910\u001b[0m       \u001b[35m0.1125\u001b[0m        \u001b[31m3.5361\u001b[0m     +  0.0010  1.3876\n",
      "      8       \u001b[36m0.0978\u001b[0m        \u001b[32m3.5374\u001b[0m       \u001b[35m0.1450\u001b[0m        \u001b[31m3.4848\u001b[0m     +  0.0010  1.3831\n",
      "      9       \u001b[36m0.1237\u001b[0m        \u001b[32m3.4864\u001b[0m       \u001b[35m0.1613\u001b[0m        \u001b[31m3.4222\u001b[0m     +  0.0010  1.4172\n",
      "     10       \u001b[36m0.1373\u001b[0m        \u001b[32m3.4402\u001b[0m       \u001b[35m0.1850\u001b[0m        \u001b[31m3.3665\u001b[0m     +  0.0010  1.4015\n",
      "     11       \u001b[36m0.1588\u001b[0m        \u001b[32m3.3871\u001b[0m       \u001b[35m0.1938\u001b[0m        \u001b[31m3.3005\u001b[0m     +  0.0010  1.3986\n",
      "     12       \u001b[36m0.1653\u001b[0m        \u001b[32m3.3343\u001b[0m       \u001b[35m0.2112\u001b[0m        \u001b[31m3.2426\u001b[0m     +  0.0010  1.3849\n",
      "     13       \u001b[36m0.1680\u001b[0m        \u001b[32m3.3016\u001b[0m       \u001b[35m0.2300\u001b[0m        \u001b[31m3.1934\u001b[0m     +  0.0010  1.3865\n",
      "     14       \u001b[36m0.1830\u001b[0m        \u001b[32m3.2542\u001b[0m       \u001b[35m0.2437\u001b[0m        \u001b[31m3.1378\u001b[0m     +  0.0010  1.4116\n",
      "     15       \u001b[36m0.2045\u001b[0m        \u001b[32m3.2014\u001b[0m       \u001b[35m0.2462\u001b[0m        \u001b[31m3.0959\u001b[0m     +  0.0010  1.4067\n",
      "     16       \u001b[36m0.2072\u001b[0m        \u001b[32m3.1595\u001b[0m       \u001b[35m0.2525\u001b[0m        \u001b[31m3.0481\u001b[0m     +  0.0010  1.3940\n",
      "     17       \u001b[36m0.2190\u001b[0m        \u001b[32m3.1164\u001b[0m       \u001b[35m0.2562\u001b[0m        \u001b[31m2.9949\u001b[0m     +  0.0010  1.4001\n",
      "     18       \u001b[36m0.2233\u001b[0m        \u001b[32m3.0755\u001b[0m       \u001b[35m0.2650\u001b[0m        \u001b[31m2.9559\u001b[0m     +  0.0010  1.4020\n",
      "     19       \u001b[36m0.2295\u001b[0m        \u001b[32m3.0437\u001b[0m       \u001b[35m0.2712\u001b[0m        \u001b[31m2.9125\u001b[0m     +  0.0010  1.4013\n",
      "     20       \u001b[36m0.2427\u001b[0m        \u001b[32m3.0059\u001b[0m       \u001b[35m0.2787\u001b[0m        \u001b[31m2.8711\u001b[0m     +  0.0010  1.4067\n",
      "     21       0.2345        \u001b[32m2.9819\u001b[0m       \u001b[35m0.2825\u001b[0m        \u001b[31m2.8405\u001b[0m     +  0.0010  1.3871\n",
      "     22       \u001b[36m0.2455\u001b[0m        \u001b[32m2.9454\u001b[0m       \u001b[35m0.2950\u001b[0m        \u001b[31m2.8006\u001b[0m     +  0.0010  1.3878\n",
      "     23       \u001b[36m0.2497\u001b[0m        \u001b[32m2.9278\u001b[0m       \u001b[35m0.3038\u001b[0m        \u001b[31m2.7777\u001b[0m     +  0.0010  1.3931\n",
      "     24       \u001b[36m0.2507\u001b[0m        \u001b[32m2.8938\u001b[0m       0.3000        \u001b[31m2.7561\u001b[0m     +  0.0010  1.3830\n",
      "     25       \u001b[36m0.2645\u001b[0m        \u001b[32m2.8568\u001b[0m       \u001b[35m0.3125\u001b[0m        \u001b[31m2.7197\u001b[0m     +  0.0010  1.3865\n",
      "     26       0.2592        \u001b[32m2.8469\u001b[0m       \u001b[35m0.3162\u001b[0m        \u001b[31m2.6853\u001b[0m     +  0.0010  1.3955\n",
      "     27       \u001b[36m0.2707\u001b[0m        \u001b[32m2.8201\u001b[0m       0.3125        \u001b[31m2.6788\u001b[0m     +  0.0010  1.3810\n",
      "     28       \u001b[36m0.2717\u001b[0m        \u001b[32m2.7866\u001b[0m       \u001b[35m0.3287\u001b[0m        \u001b[31m2.6330\u001b[0m     +  0.0010  1.4120\n",
      "     29       0.2707        2.7936       \u001b[35m0.3325\u001b[0m        \u001b[31m2.6309\u001b[0m     +  0.0010  1.4109\n",
      "     30       \u001b[36m0.2905\u001b[0m        \u001b[32m2.7441\u001b[0m       \u001b[35m0.3337\u001b[0m        \u001b[31m2.6095\u001b[0m     +  0.0010  1.3830\n",
      "     31       0.2853        \u001b[32m2.7351\u001b[0m       \u001b[35m0.3412\u001b[0m        \u001b[31m2.5783\u001b[0m     +  0.0010  1.3809\n",
      "     32       0.2820        \u001b[32m2.7264\u001b[0m       \u001b[35m0.3425\u001b[0m        \u001b[31m2.5754\u001b[0m     +  0.0010  1.3886\n",
      "     33       \u001b[36m0.2930\u001b[0m        \u001b[32m2.7220\u001b[0m       \u001b[35m0.3438\u001b[0m        \u001b[31m2.5448\u001b[0m     +  0.0010  1.3892\n",
      "     34       0.2865        \u001b[32m2.6917\u001b[0m       \u001b[35m0.3538\u001b[0m        \u001b[31m2.5289\u001b[0m     +  0.0010  1.3956\n",
      "     35       \u001b[36m0.2938\u001b[0m        \u001b[32m2.6712\u001b[0m       0.3538        \u001b[31m2.5240\u001b[0m     +  0.0010  1.4039\n",
      "     36       0.2923        \u001b[32m2.6695\u001b[0m       \u001b[35m0.3550\u001b[0m        \u001b[31m2.5037\u001b[0m     +  0.0010  1.3937\n",
      "     37       0.2908        \u001b[32m2.6586\u001b[0m       \u001b[35m0.3625\u001b[0m        \u001b[31m2.4908\u001b[0m     +  0.0010  1.4001\n",
      "     38       \u001b[36m0.3025\u001b[0m        \u001b[32m2.6238\u001b[0m       0.3625        2.4947        0.0010  1.4006\n",
      "     39       0.2985        \u001b[32m2.6225\u001b[0m       0.3625        \u001b[31m2.4644\u001b[0m     +  0.0010  1.3874\n",
      "     40       0.2983        \u001b[32m2.6158\u001b[0m       \u001b[35m0.3837\u001b[0m        \u001b[31m2.4450\u001b[0m     +  0.0010  1.3916\n",
      "     41       \u001b[36m0.3048\u001b[0m        \u001b[32m2.5923\u001b[0m       0.3663        2.4483        0.0010  1.3859\n",
      "     42       \u001b[36m0.3222\u001b[0m        \u001b[32m2.5564\u001b[0m       \u001b[35m0.3850\u001b[0m        \u001b[31m2.4281\u001b[0m     +  0.0010  1.3873\n",
      "     43       0.3083        2.5705       0.3738        \u001b[31m2.4145\u001b[0m     +  0.0010  1.4000\n",
      "     44       0.3165        \u001b[32m2.5442\u001b[0m       0.3762        2.4337        0.0009  1.3784\n",
      "     45       0.3170        2.5679       \u001b[35m0.3900\u001b[0m        \u001b[31m2.4012\u001b[0m     +  0.0009  1.3929\n",
      "     46       \u001b[36m0.3227\u001b[0m        \u001b[32m2.5409\u001b[0m       \u001b[35m0.3975\u001b[0m        2.4028        0.0009  1.3937\n",
      "     47       \u001b[36m0.3237\u001b[0m        \u001b[32m2.5251\u001b[0m       0.3750        2.4119        0.0009  1.3747\n",
      "     48       0.3230        \u001b[32m2.5224\u001b[0m       \u001b[35m0.4062\u001b[0m        \u001b[31m2.3588\u001b[0m     +  0.0009  1.3832\n",
      "     49       0.3215        2.5405       0.3987        2.3613        0.0009  1.4016\n",
      "     50       \u001b[36m0.3310\u001b[0m        \u001b[32m2.4839\u001b[0m       0.4000        2.3696        0.0009  1.3869\n",
      "     51       \u001b[36m0.3330\u001b[0m        2.5006       0.4012        \u001b[31m2.3586\u001b[0m     +  0.0009  1.3885\n",
      "     52       0.3300        2.4863       \u001b[35m0.4088\u001b[0m        \u001b[31m2.3354\u001b[0m     +  0.0009  1.3897\n",
      "     53       0.3307        \u001b[32m2.4799\u001b[0m       0.4050        \u001b[31m2.3303\u001b[0m     +  0.0009  1.3762\n",
      "     54       0.3255        2.4808       0.4088        \u001b[31m2.3175\u001b[0m     +  0.0009  1.3902\n",
      "     55       \u001b[36m0.3395\u001b[0m        \u001b[32m2.4737\u001b[0m       \u001b[35m0.4238\u001b[0m        \u001b[31m2.3077\u001b[0m     +  0.0009  1.3954\n",
      "     56       \u001b[36m0.3430\u001b[0m        \u001b[32m2.4326\u001b[0m       0.4200        \u001b[31m2.3010\u001b[0m     +  0.0009  1.3792\n",
      "     57       0.3337        2.4493       0.4163        2.3038        0.0009  1.3916\n",
      "     58       0.3395        2.4501       0.4175        \u001b[31m2.2950\u001b[0m     +  0.0009  1.3770\n",
      "     59       0.3390        2.4355       0.4138        2.3069        0.0009  1.3836\n",
      "     60       0.3412        2.4498       0.4213        2.2958        0.0009  1.3956\n",
      "     61       0.3392        2.4551       \u001b[35m0.4313\u001b[0m        \u001b[31m2.2861\u001b[0m     +  0.0009  1.3822\n",
      "     62       \u001b[36m0.3448\u001b[0m        \u001b[32m2.4204\u001b[0m       0.4238        \u001b[31m2.2799\u001b[0m     +  0.0009  1.3773\n",
      "     63       0.3415        2.4272       0.4200        \u001b[31m2.2735\u001b[0m     +  0.0009  1.3985\n",
      "     64       0.3405        \u001b[32m2.4078\u001b[0m       0.4225        \u001b[31m2.2575\u001b[0m     +  0.0009  1.3832\n",
      "     65       \u001b[36m0.3478\u001b[0m        \u001b[32m2.3937\u001b[0m       0.4225        2.2677        0.0009  1.3919\n",
      "     66       \u001b[36m0.3618\u001b[0m        \u001b[32m2.3738\u001b[0m       0.4263        \u001b[31m2.2567\u001b[0m     +  0.0009  1.4045\n",
      "     67       0.3608        2.3749       \u001b[35m0.4338\u001b[0m        \u001b[31m2.2543\u001b[0m     +  0.0009  1.3966\n",
      "     68       0.3503        2.3961       0.4325        \u001b[31m2.2271\u001b[0m     +  0.0009  1.4018\n",
      "     69       0.3563        \u001b[32m2.3635\u001b[0m       0.4325        2.2360        0.0009  1.3915\n",
      "     70       0.3478        2.3887       0.4263        2.2424        0.0009  1.3874\n",
      "     71       \u001b[36m0.3640\u001b[0m        2.3717       0.4300        2.2529        0.0009  1.3999\n",
      "     72       0.3503        2.3654       \u001b[35m0.4350\u001b[0m        2.2406        0.0009  1.3970\n",
      "     73       0.3580        \u001b[32m2.3603\u001b[0m       0.4350        \u001b[31m2.2247\u001b[0m     +  0.0009  1.3762\n",
      "     74       0.3538        2.3728       0.4350        2.2338        0.0009  1.4026\n",
      "     75       \u001b[36m0.3678\u001b[0m        \u001b[32m2.3550\u001b[0m       0.4313        \u001b[31m2.2135\u001b[0m     +  0.0009  1.4061\n",
      "     76       0.3613        2.3661       \u001b[35m0.4363\u001b[0m        \u001b[31m2.1978\u001b[0m     +  0.0009  1.3835\n",
      "     77       \u001b[36m0.3750\u001b[0m        \u001b[32m2.3041\u001b[0m       0.4225        2.2203        0.0008  1.4001\n",
      "     78       0.3650        2.3189       0.4263        2.2213        0.0008  1.3857\n",
      "     79       0.3608        2.3229       \u001b[35m0.4400\u001b[0m        \u001b[31m2.1735\u001b[0m     +  0.0008  1.3790\n",
      "     80       0.3520        2.3322       0.4400        2.2018        0.0008  1.3893\n",
      "     81       0.3728        2.3275       0.4338        2.1812        0.0008  1.3710\n",
      "     82       0.3530        2.3203       \u001b[35m0.4437\u001b[0m        2.1739        0.0008  1.3814\n",
      "     83       \u001b[36m0.3755\u001b[0m        \u001b[32m2.2998\u001b[0m       \u001b[35m0.4487\u001b[0m        \u001b[31m2.1683\u001b[0m     +  0.0008  1.4088\n",
      "     84       0.3750        \u001b[32m2.2954\u001b[0m       \u001b[35m0.4525\u001b[0m        \u001b[31m2.1598\u001b[0m     +  0.0008  1.3962\n",
      "     85       0.3728        2.3040       0.4525        2.1676        0.0008  1.4003\n",
      "     86       0.3720        2.3062       \u001b[35m0.4562\u001b[0m        2.1787        0.0008  1.4167\n",
      "     87       0.3708        \u001b[32m2.2846\u001b[0m       0.4387        2.1754        0.0008  1.3917\n",
      "     88       \u001b[36m0.3780\u001b[0m        2.2912       \u001b[35m0.4612\u001b[0m        \u001b[31m2.1369\u001b[0m     +  0.0008  1.4040\n",
      "     89       \u001b[36m0.3822\u001b[0m        \u001b[32m2.2797\u001b[0m       0.4562        2.1536        0.0008  1.4110\n",
      "     90       0.3735        2.3030       0.4537        2.1577        0.0008  1.3957\n",
      "     91       0.3738        2.2813       0.4450        2.1633        0.0008  1.4054\n",
      "     92       0.3802        \u001b[32m2.2697\u001b[0m       0.4537        2.1651        0.0008  1.3956\n",
      "     93       0.3762        2.2828       0.4587        2.1551        0.0008  1.3876\n",
      "     94       0.3723        2.2991       0.4537        2.1412        0.0008  1.3918\n",
      "     95       \u001b[36m0.3852\u001b[0m        2.2704       0.4525        2.1566        0.0008  1.3874\n",
      "     96       \u001b[36m0.3965\u001b[0m        \u001b[32m2.2510\u001b[0m       \u001b[35m0.4650\u001b[0m        2.1372        0.0008  1.3917\n",
      "     97       0.3752        2.2781       0.4625        2.1458        0.0008  1.4127\n",
      "     98       0.3757        2.2895       0.4550        2.1442        0.0008  1.4032\n",
      "     99       0.3875        2.2518       0.4562        2.1557        0.0008  1.3884\n",
      "    100       0.3807        2.2511       0.4512        2.1468        0.0008  1.3893\n",
      "    101       0.3815        \u001b[32m2.2429\u001b[0m       0.4512        2.1424        0.0007  1.3748\n",
      "    102       0.3882        2.2720       0.4537        2.1389        0.0007  1.3793\n",
      "    103       0.3830        2.2477       0.4575        \u001b[31m2.1155\u001b[0m     +  0.0007  1.3861\n",
      "    104       0.3847        2.2451       0.4475        2.1256        0.0007  1.3891\n",
      "    105       0.3935        \u001b[32m2.2229\u001b[0m       0.4637        \u001b[31m2.0965\u001b[0m     +  0.0007  1.3918\n",
      "    106       0.3965        2.2390       \u001b[35m0.4725\u001b[0m        \u001b[31m2.0876\u001b[0m     +  0.0007  1.4014\n",
      "    107       0.3942        2.2434       0.4637        2.1091        0.0007  1.3854\n",
      "    108       0.3942        \u001b[32m2.2225\u001b[0m       0.4675        2.0976        0.0007  1.3928\n",
      "    109       0.3965        \u001b[32m2.2140\u001b[0m       0.4600        2.1171        0.0007  1.3999\n",
      "    110       0.3907        2.2507       0.4587        2.1166        0.0007  1.3833\n",
      "    111       0.3890        2.2547       0.4562        2.1009        0.0007  1.3843\n",
      "    112       0.3887        2.2269       0.4600        2.1019        0.0007  1.3861\n",
      "    113       0.3940        2.2223       0.4625        2.0920        0.0007  1.3751\n",
      "    114       0.3915        \u001b[32m2.2124\u001b[0m       0.4562        2.1043        0.0007  1.4001\n",
      "    115       0.3960        2.2423       0.4537        2.1107        0.0007  1.4041\n",
      "    116       0.3880        2.2424       0.4600        2.1054        0.0007  1.3958\n",
      "    117       0.3815        2.2659       0.4612        2.1025        0.0007  1.3832\n",
      "    118       \u001b[36m0.4007\u001b[0m        \u001b[32m2.1945\u001b[0m       0.4662        2.1010        0.0007  1.3886\n",
      "    119       0.3937        2.2233       0.4612        2.1070        0.0007  1.3842\n",
      "    120       0.3857        2.2348       0.4688        2.1038        0.0007  1.4102\n",
      "    121       0.3875        2.2496       0.4612        2.0933        0.0007  1.3881\n",
      "    122       0.3930        2.2241       \u001b[35m0.4800\u001b[0m        \u001b[31m2.0771\u001b[0m     +  0.0006  1.3756\n",
      "    123       0.3987        2.2221       0.4612        2.0961        0.0006  1.3961\n",
      "    124       0.3952        2.2235       0.4750        \u001b[31m2.0656\u001b[0m     +  0.0006  1.3980\n",
      "    125       0.3965        2.2050       0.4688        2.0819        0.0006  1.3956\n",
      "    126       0.3950        2.2199       0.4650        2.0838        0.0006  1.4103\n",
      "    127       0.3960        \u001b[32m2.1911\u001b[0m       0.4750        2.0733        0.0006  1.3783\n",
      "    128       0.3942        2.2132       0.4738        2.0876        0.0006  1.3922\n",
      "    129       0.3950        \u001b[32m2.1876\u001b[0m       0.4713        \u001b[31m2.0574\u001b[0m     +  0.0006  1.3953\n",
      "    130       \u001b[36m0.4010\u001b[0m        2.1918       0.4738        2.0812        0.0006  1.3737\n",
      "    131       \u001b[36m0.4185\u001b[0m        \u001b[32m2.1674\u001b[0m       0.4725        2.0800        0.0006  1.3933\n",
      "    132       0.3972        2.2095       0.4738        2.0658        0.0006  1.3981\n",
      "    133       0.3960        2.1901       0.4725        2.0622        0.0006  1.3982\n",
      "    134       0.3947        2.2110       0.4725        2.0665        0.0006  1.4127\n",
      "    135       0.4120        2.1820       \u001b[35m0.4838\u001b[0m        \u001b[31m2.0338\u001b[0m     +  0.0006  1.4042\n",
      "    136       0.3995        2.2093       0.4788        2.0498        0.0006  1.4073\n",
      "    137       0.4160        \u001b[32m2.1602\u001b[0m       \u001b[35m0.4850\u001b[0m        2.0527        0.0006  1.3999\n",
      "    138       0.4040        2.1782       0.4775        2.0481        0.0006  1.3842\n",
      "    139       0.4012        2.1715       0.4738        2.0563        0.0006  1.3934\n",
      "    140       0.4108        2.1944       0.4738        2.0630        0.0006  1.4064\n",
      "    141       0.4025        2.1925       0.4788        2.0416        0.0005  1.3885\n",
      "    142       0.4170        2.1631       0.4800        2.0407        0.0005  1.3793\n",
      "    143       0.4078        2.1629       0.4763        2.0468        0.0005  1.3927\n",
      "    144       0.4133        2.1768       0.4750        2.0484        0.0005  1.3845\n",
      "    145       0.4118        2.1946       0.4738        2.0503        0.0005  1.4042\n",
      "    146       0.4083        2.1843       0.4750        2.0445        0.0005  1.4166\n",
      "    147       0.3967        2.1917       0.4788        2.0425        0.0005  1.3958\n",
      "    148       0.4022        2.1984       0.4788        \u001b[31m2.0315\u001b[0m     +  0.0005  1.4078\n",
      "    149       0.4078        2.1782       0.4738        2.0528        0.0005  1.4129\n",
      "    150       0.4057        2.1784       0.4800        2.0393        0.0005  1.3857\n",
      "    151       0.4075        2.1695       0.4750        2.0329        0.0005  1.4103\n",
      "    152       0.3977        2.1833       0.4763        \u001b[31m2.0291\u001b[0m     +  0.0005  1.4123\n",
      "    153       0.4105        2.1674       0.4825        2.0354        0.0005  1.3929\n",
      "    154       0.4057        2.1850       \u001b[35m0.4888\u001b[0m        \u001b[31m2.0112\u001b[0m     +  0.0005  1.3919\n",
      "    155       0.4153        2.1626       0.4875        2.0447        0.0005  1.3877\n",
      "    156       0.4088        \u001b[32m2.1532\u001b[0m       0.4863        2.0289        0.0005  1.3871\n",
      "    157       0.4090        2.1601       0.4825        2.0383        0.0005  1.3921\n",
      "    158       0.4103        \u001b[32m2.1509\u001b[0m       0.4863        2.0284        0.0005  1.3805\n",
      "    159       0.4158        \u001b[32m2.1290\u001b[0m       \u001b[35m0.4913\u001b[0m        2.0309        0.0005  1.4011\n",
      "    160       0.4178        2.1472       0.4850        2.0216        0.0005  1.3996\n",
      "    161       0.4115        \u001b[32m2.1264\u001b[0m       0.4863        2.0266        0.0004  1.3958\n",
      "    162       0.4093        2.1651       0.4800        2.0131        0.0004  1.3917\n",
      "    163       0.4050        2.1751       0.4713        2.0228        0.0004  1.3891\n",
      "    164       0.4118        2.1708       0.4850        2.0146        0.0004  1.3841\n",
      "    165       0.4098        2.1440       0.4875        2.0189        0.0004  1.3857\n",
      "    166       0.3992        2.1598       0.4850        2.0171        0.0004  1.3852\n",
      "    167       0.4098        2.1442       0.4838        \u001b[31m2.0054\u001b[0m     +  0.0004  1.3858\n",
      "    168       0.4108        2.1602       0.4888        2.0079        0.0004  1.3998\n",
      "    169       0.4148        2.1779       0.4863        2.0094        0.0004  1.3991\n",
      "    170       0.4088        2.1808       0.4900        2.0211        0.0004  1.3859\n",
      "    171       0.4185        2.1610       0.4913        2.0159        0.0004  1.4046\n",
      "    172       0.4165        2.1376       0.4913        2.0199        0.0004  1.3895\n",
      "    173       0.4020        2.1429       0.4875        2.0174        0.0004  1.4043\n",
      "    174       \u001b[36m0.4218\u001b[0m        2.1573       0.4863        2.0102        0.0004  1.4128\n",
      "    175       0.4123        2.1421       0.4875        2.0063        0.0004  1.4059\n",
      "    176       0.4135        2.1470       0.4913        \u001b[31m1.9995\u001b[0m     +  0.0004  1.4007\n",
      "    177       0.4168        2.1337       0.4900        2.0131        0.0004  1.3986\n",
      "    178       0.4110        2.1418       0.4838        2.0036        0.0004  1.3872\n",
      "    179       0.4027        2.1468       0.4825        2.0017        0.0004  1.3815\n",
      "    180       \u001b[36m0.4263\u001b[0m        \u001b[32m2.1219\u001b[0m       0.4838        1.9996        0.0003  1.4001\n",
      "    181       0.4223        2.1308       0.4838        \u001b[31m1.9953\u001b[0m     +  0.0003  1.3874\n",
      "    182       0.4168        2.1432       0.4825        \u001b[31m1.9933\u001b[0m     +  0.0003  1.3867\n",
      "    183       0.4088        2.1536       0.4850        2.0098        0.0003  1.4097\n",
      "    184       0.4017        2.1387       0.4825        2.0045        0.0003  1.3867\n",
      "    185       0.4090        2.1542       0.4850        2.0040        0.0003  1.3916\n",
      "    186       0.4153        2.1226       0.4800        1.9945        0.0003  1.3939\n",
      "    187       0.4178        2.1276       0.4863        2.0011        0.0003  1.3830\n",
      "    188       0.4178        2.1381       0.4850        1.9997        0.0003  1.3927\n",
      "    189       0.4158        2.1229       0.4825        1.9979        0.0003  1.4205\n",
      "    190       0.4253        2.1276       0.4900        \u001b[31m1.9932\u001b[0m     +  0.0003  1.4019\n",
      "    191       0.4133        2.1355       0.4863        2.0028        0.0003  1.4152\n",
      "    192       0.4140        2.1429       0.4913        1.9944        0.0003  1.3905\n",
      "    193       0.4153        \u001b[32m2.1141\u001b[0m       0.4900        1.9943        0.0003  1.3934\n",
      "    194       0.4148        2.1192       0.4863        \u001b[31m1.9865\u001b[0m     +  0.0003  1.3873\n",
      "    195       \u001b[36m0.4273\u001b[0m        \u001b[32m2.1105\u001b[0m       0.4913        1.9904        0.0003  1.3892\n",
      "    196       0.4273        \u001b[32m2.1031\u001b[0m       \u001b[35m0.4963\u001b[0m        \u001b[31m1.9833\u001b[0m     +  0.0003  1.3961\n",
      "    197       0.4080        2.1566       0.4863        1.9960        0.0003  1.3967\n",
      "    198       \u001b[36m0.4345\u001b[0m        2.1069       0.4863        1.9941        0.0003  1.3786\n",
      "    199       0.4233        2.1144       0.4825        2.0034        0.0003  1.3875\n",
      "    200       0.4250        2.1137       0.4888        1.9885        0.0003  1.4052\n",
      "    201       0.4248        2.1355       0.4950        1.9868        0.0002  1.3813\n",
      "    202       0.4240        2.1226       0.4963        \u001b[31m1.9757\u001b[0m     +  0.0002  1.3939\n",
      "    203       0.4180        2.1165       \u001b[35m0.4988\u001b[0m        1.9806        0.0002  1.3935\n",
      "    204       0.4185        2.1121       0.4950        \u001b[31m1.9705\u001b[0m     +  0.0002  1.3804\n",
      "    205       0.4265        2.1184       0.4938        1.9807        0.0002  1.4045\n",
      "    206       0.4123        2.1376       0.4963        1.9873        0.0002  1.3961\n",
      "    207       0.4138        2.1514       0.4938        1.9862        0.0002  1.3834\n",
      "    208       0.4093        2.1232       0.4925        1.9881        0.0002  1.3845\n",
      "    209       0.4203        2.1206       0.4963        1.9746        0.0002  1.3849\n",
      "    210       0.4175        2.1271       0.4950        1.9726        0.0002  1.3758\n",
      "    211       0.4238        2.1430       0.4850        1.9911        0.0002  1.3958\n",
      "    212       0.4163        2.1456       0.4925        1.9932        0.0002  1.3834\n",
      "    213       0.4203        2.1195       0.4850        1.9938        0.0002  1.3822\n",
      "    214       0.4210        2.1331       0.4875        1.9967        0.0002  1.3998\n",
      "    215       0.4220        2.1329       0.4938        1.9895        0.0002  1.3853\n",
      "    216       0.4228        2.1102       0.4900        1.9895        0.0002  1.4083\n",
      "    217       0.4173        2.1198       0.4900        1.9824        0.0002  1.3977\n",
      "    218       0.4205        2.1312       0.4938        1.9766        0.0002  1.3797\n",
      "    219       0.4215        2.1058       0.4838        1.9776        0.0002  1.4077\n",
      "    220       0.4205        2.1044       0.4850        1.9848        0.0002  1.4215\n",
      "    221       0.4273        \u001b[32m2.1022\u001b[0m       0.4925        1.9786        0.0002  1.4000\n",
      "    222       0.4198        2.1090       0.4888        1.9781        0.0002  1.3980\n",
      "    223       0.4140        2.1307       0.4975        \u001b[31m1.9684\u001b[0m     +  0.0002  1.3940\n",
      "    224       0.4183        2.1272       0.4925        1.9807        0.0002  1.3833\n",
      "    225       \u001b[36m0.4360\u001b[0m        \u001b[32m2.1017\u001b[0m       0.4963        \u001b[31m1.9677\u001b[0m     +  0.0001  1.3950\n",
      "    226       0.4275        \u001b[32m2.0975\u001b[0m       0.4963        1.9720        0.0001  1.4168\n",
      "    227       0.4263        \u001b[32m2.0883\u001b[0m       \u001b[35m0.5000\u001b[0m        1.9685        0.0001  1.3952\n",
      "    228       0.4188        2.1360       0.4988        1.9752        0.0001  1.4065\n",
      "    229       0.4263        2.1055       0.4938        1.9847        0.0001  1.3917\n",
      "    230       0.4188        2.1256       0.4963        1.9835        0.0001  1.3789\n",
      "    231       0.4203        2.1035       0.4963        1.9765        0.0001  1.4005\n",
      "    232       0.4213        2.1057       0.4900        1.9860        0.0001  1.3888\n",
      "    233       0.4148        2.1251       0.4963        1.9800        0.0001  1.3863\n",
      "    234       0.4260        2.1180       0.4938        1.9772        0.0001  1.3997\n",
      "    235       0.4138        2.1396       0.4900        1.9850        0.0001  1.3853\n",
      "    236       0.4178        2.1301       0.4938        1.9733        0.0001  1.3943\n",
      "    237       0.4265        2.1018       0.4938        1.9700        0.0001  1.4063\n",
      "    238       0.4248        2.1125       0.4963        1.9744        0.0001  1.3873\n",
      "    239       0.4225        2.1052       0.4938        \u001b[31m1.9623\u001b[0m     +  0.0001  1.3833\n",
      "    240       0.4263        2.1127       0.4975        \u001b[31m1.9599\u001b[0m     +  0.0001  1.3972\n",
      "    241       0.4178        2.1107       0.4938        1.9681        0.0001  1.3875\n",
      "    242       0.4203        2.1214       0.4975        1.9633        0.0001  1.3873\n",
      "    243       0.4340        2.0888       0.4975        1.9737        0.0001  1.4028\n",
      "    244       0.4275        2.0972       0.4950        1.9747        0.0001  1.3914\n",
      "    245       0.4200        2.0922       0.4950        1.9726        0.0001  1.4050\n",
      "    246       0.4280        2.0972       0.4925        1.9715        0.0001  1.4097\n",
      "    247       0.4185        2.1198       0.4938        1.9809        0.0001  1.3960\n",
      "    248       0.4223        2.1245       0.4950        1.9710        0.0001  1.4167\n",
      "    249       0.4200        2.1371       0.4913        1.9760        0.0001  1.3993\n",
      "    250       0.4248        2.1184       0.4975        1.9725        0.0001  1.3990\n",
      "    251       0.4248        2.1122       0.4925        1.9704        0.0001  1.4124\n",
      "    252       0.4245        2.0929       0.4950        1.9696        0.0001  1.4026\n",
      "    253       0.4208        2.1018       0.4963        1.9739        0.0001  1.4100\n",
      "    254       0.4210        2.1059       0.4975        1.9741        0.0001  1.4071\n",
      "    255       0.4333        \u001b[32m2.0727\u001b[0m       0.4963        1.9672        0.0001  1.3958\n",
      "    256       0.4323        2.1067       0.4988        1.9734        0.0001  1.4084\n",
      "    257       0.4358        2.0938       0.4975        1.9735        0.0001  1.4153\n",
      "    258       0.4245        2.0834       0.4963        1.9710        0.0000  1.3874\n",
      "    259       0.4248        2.1027       0.4975        1.9756        0.0000  1.3961\n",
      "    260       \u001b[36m0.4405\u001b[0m        2.0869       0.4975        1.9745        0.0000  1.4151\n",
      "    261       0.4245        2.1117       0.4988        1.9659        0.0000  1.4140\n",
      "    262       0.4290        2.0980       0.4988        1.9677        0.0000  1.4234\n",
      "    263       0.4288        2.0945       0.4988        1.9694        0.0000  1.4000\n",
      "    264       0.4238        2.0970       0.5000        1.9695        0.0000  1.3833\n",
      "    265       0.4115        2.1464       0.4938        1.9796        0.0000  1.4001\n",
      "    266       0.4285        2.0969       0.4988        1.9761        0.0000  1.4053\n",
      "    267       0.4235        2.0918       0.4975        1.9667        0.0000  1.3904\n",
      "    268       0.4318        2.0821       0.4988        1.9770        0.0000  1.3917\n",
      "    269       0.4370        2.0824       0.4988        1.9671        0.0000  1.3859\n",
      "    270       0.4265        2.0921       0.4988        1.9678        0.0000  1.3955\n",
      "    271       0.4158        2.1148       0.4975        1.9683        0.0000  1.4067\n",
      "    272       0.4195        2.1200       0.4938        1.9860        0.0000  1.3967\n",
      "    273       0.4153        2.1374       0.4975        1.9677        0.0000  1.4029\n",
      "    274       0.4228        2.1045       0.4963        1.9675        0.0000  1.4150\n",
      "    275       0.4270        2.1172       0.4988        1.9688        0.0000  1.3877\n",
      "    276       0.4323        2.0903       0.4975        1.9706        0.0000  1.3863\n",
      "    277       0.4248        2.0971       0.4988        1.9713        0.0000  1.4028\n",
      "    278       0.4283        2.0768       0.5000        1.9727        0.0000  1.3933\n",
      "    279       0.4230        2.1092       0.4975        1.9714        0.0000  1.3915\n",
      "    280       0.4280        2.1118       0.4988        1.9688        0.0000  1.4090\n",
      "    281       0.4243        2.1162       0.4988        1.9640        0.0000  1.3921\n",
      "    282       0.4330        2.0919       0.4950        1.9709        0.0000  1.4033\n",
      "    283       0.4138        2.1199       0.4988        1.9632        0.0000  1.4016\n",
      "    284       0.4350        2.1040       0.4988        1.9674        0.0000  1.3936\n",
      "    285       0.4363        2.0775       0.4963        1.9721        0.0000  1.3972\n",
      "    286       0.4298        2.1022       0.4988        1.9692        0.0000  1.3915\n",
      "    287       0.4255        2.0938       0.4975        1.9659        0.0000  1.3879\n",
      "    288       \u001b[36m0.4407\u001b[0m        2.0853       0.4963        1.9776        0.0000  1.4032\n",
      "    289       0.4265        2.0769       0.4975        1.9679        0.0000  1.3876\n",
      "Stopping since valid_loss has not improved in the last 50 epochs.\n",
      "预测频率： ['8.0', '9.0', '10.0', '10.4', '11.0', '12.4', '13.4', '11.8', '8.2', '9.2', '10.2', '11.2', '11.8', '11.6', '14.2', '13.4', '8.4', '9.4', '10.4', '10.8', '12.4', '13.4', '13.2', '14.2', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.0', '13.0', '8.8', '9.8', '10.8', '11.8', '12.8', '13.2', '14.8', '10.8', '13.2', '13.0', '10.8', '10.4', '12.0', '13.0', '14.6', '14.6', '8.2', '9.2', '12.4', '10.8', '10.8', '12.8', '11.4', '14.4', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '13.4', '14.6', '9.4', '10.6', '10.6', '11.6', '12.6', '12.6', '12.2', '14.8', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '13.4', '9.0', '11.4', '11.0', '12.0', '13.0', '13.4', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '12.6', '14.2', '14.8', '9.8', '9.4', '10.4', '10.8', '12.4', '13.4', '14.4', '13.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '14.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '9.0', '9.0', '10.0', '11.4', '12.4', '12.4', '13.4', '12.2', '10.8', '9.2', '10.2', '12.6', '12.8', '13.2', '14.6', '10.6', '12.2', '9.4', '10.4', '11.4', '11.8', '13.2', '13.8', '8.8', '11.4', '9.6', '10.6', '11.0', '12.6', '8.8', '14.0', '8.6', '8.8', '9.8', '10.8', '11.2', '12.8', '13.6', '14.8', '10.4', '12.2', '10.0', '10.0', '12.0', '13.6', '13.0', '14.0', '15.0', '10.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '9.4', '11.4', '10.4', '12.4', '12.4', '13.4', '14.4', '14.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '13.6', '8.8', '9.2', '10.8', '9.8', '12.8', '13.8', '14.8', '15.8', '13.0', '9.0', '10.0', '11.0', '12.0', '13.0', '13.6', '12.4', '8.2', '9.2', '9.8', '11.2', '12.8', '13.8', '13.8', '15.2', '12.0', '11.4', '10.4', '11.4', '12.4', '13.4', '14.4', '14.4', '12.6', '9.6', '13.4', '13.0', '12.8', '13.6', '14.6', '14.6', '8.8', '9.8', '11.2', '11.8', '13.4', '13.8', '15.4', '14.6', '8.0', '12.0', '10.6', '10.6', '11.6', '13.0', '14.0', '14.0', '11.6', '9.6', '9.2', '10.8', '11.2', '13.2', '13.6', '8.8', '11.2', '9.0', '10.4', '11.4', '12.4', '13.4', '13.4', '11.0', '8.6', '9.6', '10.6', '11.6', '12.0', '13.6', '14.0', '11.4', '8.8', '9.8', '10.8', '11.8', '12.0', '12.8', '14.2', '13.8', '10.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.6', '9.2', '10.2', '11.8', '12.2', '12.8', '13.8', '15.2', '8.4', '9.6', '10.4', '11.0', '12.4', '13.4', '14.4', '15.6', '8.6', '9.6', '10.6', '12.6', '9.8', '13.6', '14.6', '14.4', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '13.4', '15.8', '8.0', '9.0', '10.0', '10.8', '12.6', '13.6', '11.6', '12.0', '9.2', '8.8', '10.2', '11.2', '12.2', '10.4', '14.0', '10.4', '9.4', '9.4', '10.4', '11.4', '12.4', '13.8', '12.2', '11.6', '11.8', '9.6', '10.6', '12.0', '11.0', '13.6', '14.6', '12.4', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '13.4', '12.2', '9.0', '10.0', '12.0', '12.6', '13.6', '13.0', '9.8', '9.2', '9.2', '10.2', '11.2', '12.8', '13.8', '14.2', '15.2', '9.6', '9.4', '12.6', '11.4', '13.0', '13.4', '14.4', '13.6', '9.0', '9.6', '10.6', '11.6', '12.6', '13.6', '9.6', '10.8', '8.8', '9.8', '10.8', '11.8', '12.8', '12.8', '12.0', '9.0', '11.4', '11.6', '13.4', '12.6', '11.6', '11.6', '13.6', '12.4', '12.2', '10.2', '11.2', '12.6', '10.8', '9.2', '12.8', '13.8', '12.2', '14.6', '8.6', '12.4', '13.0', '11.4', '10.8', '10.8', '11.6', '14.4', '10.6', '12.4', '12.8', '12.2', '13.0', '11.4', '12.0', '9.8', '9.4', '10.0', '12.8', '13.8', '14.8', '9.8', '10.0', '9.0', '10.0', '11.6', '12.6', '12.6', '13.6', '14.6', '13.4', '11.0', '10.2', '10.8', '11.8', '12.8', '13.2', '10.0', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.6', '12.6', '8.6', '9.6', '10.6', '11.6', '12.6', '13.2', '14.6', '11.8', '9.4', '9.8', '10.8', '11.8', '12.8', '13.8', '13.4', '15.8', '9.0', '9.6', '10.6', '11.0', '10.4', '11.4', '14.0', '14.0', '9.2', '9.6', '10.2', '9.2', '14.6', '13.2', '14.2', '14.8', '10.2', '9.2', '10.4', '10.4', '11.4', '12.4', '13.0', '14.4', '12.4', '9.6', '8.8', '9.2', '8.4', '8.8', '14.0', '15.6', '13.2', '9.8', '11.8', '11.2', '12.8', '13.8', '9.8', '9.4', '13.0', '9.6', '10.0', '10.0', '11.4', '13.0', '14.0', '11.4', '8.2', '9.2', '10.2', '10.6', '12.2', '13.2', '13.6', '15.0', '10.4', '12.6', '10.4', '11.4', '12.4', '13.4', '14.4', '14.4', '8.6', '9.6', '10.0', '11.6', '12.6', '13.0', '9.6', '15.0', '9.6', '9.8', '11.2', '11.8', '12.8', '13.8', '14.8', '11.2', '9.0', '9.0', '10.0', '11.0', '12.6', '8.2', '14.0', '14.0', '8.8', '9.2', '10.8', '10.6', '12.8', '13.2', '13.2', '11.2', '8.4', '9.4', '11.8', '11.4', '12.4', '13.4', '11.6', '14.4', '15.0', '9.6', '10.6', '11.6', '12.0', '13.6', '14.0', '14.2', '8.8', '9.8', '10.8', '11.8', '13.2', '13.8', '14.8', '11.4', '15.8', '9.6', '10.0', '11.0', '12.0', '13.0', '11.8', '15.0', '8.2', '9.2', '11.2', '10.6', '11.8', '12.6', '13.6', '11.8', '9.4', '8.8', '11.4', '11.4', '13.4', '11.6', '13.8', '14.8', '12.0', '9.6', '11.6', '11.6', '12.6', '13.4', '13.4', '15.6', '11.4', '11.2', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '14.0', '9.0', '10.0', '11.4', '12.4', '13.0', '14.0', '15.0', '8.8', '9.2', '10.8', '11.6', '9.0', '13.8', '14.2', '14.6', '13.4', '9.4', '9.8', '12.4', '13.8', '13.4', '14.8', '14.4', '8.6', '9.6', '10.6', '12.0', '13.0', '13.6', '14.6', '13.8', '8.8', '9.8', '10.8', '12.2', '12.8', '13.8', '14.0', '15.8', '12.8', '9.8', '10.0', '11.8', '12.8', '13.0', '9.0', '11.8', '9.2', '10.4', '10.2', '10.6', '12.8', '13.2', '14.2', '15.4', '8.4', '10.4', '11.0', '11.4', '12.4', '13.4', '15.0', '9.6', '8.8', '9.6', '10.8', '11.6', '12.6', '13.6', '14.6', '10.6', '8.8', '9.8', '10.8', '11.2', '12.8', '13.8', '14.8', '13.6', '14.4', '9.0', '12.0', '11.8', '11.0', '10.2', '12.0', '14.2', '8.2', '10.4', '10.2', '11.2', '12.2', '13.2', '13.4', '13.8', '9.4', '9.4', '9.2', '11.4', '11.4', '13.4', '12.4', '11.6', '8.6', '9.6', '10.6', '9.6', '12.6', '13.8', '13.6', '11.0', '8.8', '9.2', '10.8', '12.2', '13.2', '14.2', '13.4', '12.6', '10.0', '12.6', '10.6', '11.0', '12.0', '9.4', '13.4', '8.8', '8.8', '9.6', '10.2', '11.2', '12.2', '12.8', '14.2', '10.0', '8.8', '13.2', '10.4', '12.2', '12.4', '13.4', '13.0', '10.8', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '13.4', '10.4', '9.2', '9.8', '13.2', '13.2', '10.8', '10.6', '10.6', '14.0']\n",
      "真实频率： ['8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8']\n",
      "第1折准确率: 0.4975\n",
      "train_ind数量: 4000, validate_ind数量: 800, test_ind数量: 800\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      lr     dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  ------  ------\n",
      "      1       \u001b[36m0.0265\u001b[0m        \u001b[32m3.7600\u001b[0m       \u001b[35m0.0450\u001b[0m        \u001b[31m3.6766\u001b[0m     +  0.0010  1.4124\n",
      "      2       \u001b[36m0.0328\u001b[0m        \u001b[32m3.7067\u001b[0m       \u001b[35m0.0688\u001b[0m        \u001b[31m3.6534\u001b[0m     +  0.0010  1.3955\n",
      "      3       \u001b[36m0.0447\u001b[0m        \u001b[32m3.6762\u001b[0m       \u001b[35m0.0850\u001b[0m        \u001b[31m3.6304\u001b[0m     +  0.0010  1.3963\n",
      "      4       \u001b[36m0.0570\u001b[0m        \u001b[32m3.6433\u001b[0m       \u001b[35m0.0975\u001b[0m        \u001b[31m3.6015\u001b[0m     +  0.0010  1.4060\n",
      "      5       \u001b[36m0.0720\u001b[0m        \u001b[32m3.6207\u001b[0m       \u001b[35m0.1163\u001b[0m        \u001b[31m3.5664\u001b[0m     +  0.0010  1.3871\n",
      "      6       \u001b[36m0.0855\u001b[0m        \u001b[32m3.5695\u001b[0m       \u001b[35m0.1400\u001b[0m        \u001b[31m3.5183\u001b[0m     +  0.0010  1.3916\n",
      "      7       \u001b[36m0.0958\u001b[0m        \u001b[32m3.5372\u001b[0m       \u001b[35m0.1525\u001b[0m        \u001b[31m3.4702\u001b[0m     +  0.0010  1.3998\n",
      "      8       \u001b[36m0.1128\u001b[0m        \u001b[32m3.4919\u001b[0m       \u001b[35m0.1775\u001b[0m        \u001b[31m3.4179\u001b[0m     +  0.0010  1.3946\n",
      "      9       \u001b[36m0.1263\u001b[0m        \u001b[32m3.4542\u001b[0m       \u001b[35m0.1825\u001b[0m        \u001b[31m3.3536\u001b[0m     +  0.0010  1.4002\n",
      "     10       \u001b[36m0.1388\u001b[0m        \u001b[32m3.4032\u001b[0m       \u001b[35m0.2062\u001b[0m        \u001b[31m3.3006\u001b[0m     +  0.0010  1.3915\n",
      "     11       \u001b[36m0.1560\u001b[0m        \u001b[32m3.3480\u001b[0m       0.2062        \u001b[31m3.2462\u001b[0m     +  0.0010  1.4013\n",
      "     12       \u001b[36m0.1685\u001b[0m        \u001b[32m3.2965\u001b[0m       \u001b[35m0.2225\u001b[0m        \u001b[31m3.1797\u001b[0m     +  0.0010  1.4029\n",
      "     13       \u001b[36m0.1810\u001b[0m        \u001b[32m3.2379\u001b[0m       0.2213        \u001b[31m3.1177\u001b[0m     +  0.0010  1.3858\n",
      "     14       \u001b[36m0.1920\u001b[0m        \u001b[32m3.2034\u001b[0m       \u001b[35m0.2263\u001b[0m        \u001b[31m3.0558\u001b[0m     +  0.0010  1.4000\n",
      "     15       \u001b[36m0.1995\u001b[0m        \u001b[32m3.1571\u001b[0m       \u001b[35m0.2400\u001b[0m        \u001b[31m3.0045\u001b[0m     +  0.0010  1.3955\n",
      "     16       \u001b[36m0.2130\u001b[0m        \u001b[32m3.1089\u001b[0m       \u001b[35m0.2525\u001b[0m        \u001b[31m2.9692\u001b[0m     +  0.0010  1.3872\n",
      "     17       \u001b[36m0.2132\u001b[0m        \u001b[32m3.0871\u001b[0m       \u001b[35m0.2612\u001b[0m        \u001b[31m2.9190\u001b[0m     +  0.0010  1.3911\n",
      "     18       \u001b[36m0.2293\u001b[0m        \u001b[32m3.0269\u001b[0m       \u001b[35m0.2662\u001b[0m        \u001b[31m2.8688\u001b[0m     +  0.0010  1.4000\n",
      "     19       \u001b[36m0.2298\u001b[0m        \u001b[32m2.9918\u001b[0m       \u001b[35m0.2750\u001b[0m        \u001b[31m2.8235\u001b[0m     +  0.0010  1.3833\n",
      "     20       \u001b[36m0.2500\u001b[0m        \u001b[32m2.9390\u001b[0m       \u001b[35m0.2775\u001b[0m        \u001b[31m2.8003\u001b[0m     +  0.0010  1.4082\n",
      "     21       0.2457        \u001b[32m2.9182\u001b[0m       \u001b[35m0.2850\u001b[0m        \u001b[31m2.7626\u001b[0m     +  0.0010  1.4065\n",
      "     22       \u001b[36m0.2540\u001b[0m        \u001b[32m2.8773\u001b[0m       \u001b[35m0.2925\u001b[0m        \u001b[31m2.7384\u001b[0m     +  0.0010  1.3998\n",
      "     23       \u001b[36m0.2545\u001b[0m        \u001b[32m2.8649\u001b[0m       \u001b[35m0.3038\u001b[0m        \u001b[31m2.6990\u001b[0m     +  0.0010  1.4101\n",
      "     24       \u001b[36m0.2612\u001b[0m        \u001b[32m2.8184\u001b[0m       \u001b[35m0.3113\u001b[0m        \u001b[31m2.6687\u001b[0m     +  0.0010  1.3880\n",
      "     25       \u001b[36m0.2685\u001b[0m        \u001b[32m2.8174\u001b[0m       0.3025        \u001b[31m2.6574\u001b[0m     +  0.0010  1.3959\n",
      "     26       0.2662        \u001b[32m2.7960\u001b[0m       \u001b[35m0.3175\u001b[0m        \u001b[31m2.6340\u001b[0m     +  0.0010  1.3999\n",
      "     27       \u001b[36m0.2745\u001b[0m        \u001b[32m2.7650\u001b[0m       \u001b[35m0.3400\u001b[0m        \u001b[31m2.5877\u001b[0m     +  0.0010  1.3891\n",
      "     28       \u001b[36m0.2845\u001b[0m        \u001b[32m2.7513\u001b[0m       0.3337        \u001b[31m2.5803\u001b[0m     +  0.0010  1.3980\n",
      "     29       0.2820        \u001b[32m2.7330\u001b[0m       0.3400        \u001b[31m2.5715\u001b[0m     +  0.0010  1.3952\n",
      "     30       \u001b[36m0.2910\u001b[0m        \u001b[32m2.7020\u001b[0m       \u001b[35m0.3625\u001b[0m        \u001b[31m2.5499\u001b[0m     +  0.0010  1.3867\n",
      "     31       \u001b[36m0.2915\u001b[0m        \u001b[32m2.6876\u001b[0m       \u001b[35m0.3638\u001b[0m        \u001b[31m2.5101\u001b[0m     +  0.0010  1.3946\n",
      "     32       \u001b[36m0.2983\u001b[0m        \u001b[32m2.6622\u001b[0m       0.3563        \u001b[31m2.4988\u001b[0m     +  0.0010  1.3985\n",
      "     33       0.2885        \u001b[32m2.6521\u001b[0m       0.3525        2.5120        0.0010  1.3876\n",
      "     34       0.2978        2.6528       0.3563        \u001b[31m2.4722\u001b[0m     +  0.0010  1.3899\n",
      "     35       \u001b[36m0.3043\u001b[0m        \u001b[32m2.6174\u001b[0m       \u001b[35m0.3725\u001b[0m        \u001b[31m2.4621\u001b[0m     +  0.0010  1.4007\n",
      "     36       0.2960        2.6245       \u001b[35m0.3825\u001b[0m        \u001b[31m2.4567\u001b[0m     +  0.0010  1.3827\n",
      "     37       \u001b[36m0.3125\u001b[0m        \u001b[32m2.6162\u001b[0m       0.3800        \u001b[31m2.4493\u001b[0m     +  0.0010  1.3977\n",
      "     38       0.3030        \u001b[32m2.6062\u001b[0m       \u001b[35m0.3900\u001b[0m        \u001b[31m2.4288\u001b[0m     +  0.0010  1.4015\n",
      "     39       0.3075        \u001b[32m2.5783\u001b[0m       0.3688        2.4290        0.0010  1.3960\n",
      "     40       0.3073        2.5868       0.3887        \u001b[31m2.4095\u001b[0m     +  0.0010  1.3917\n",
      "     41       0.3055        \u001b[32m2.5472\u001b[0m       0.3825        \u001b[31m2.4072\u001b[0m     +  0.0010  1.3911\n",
      "     42       \u001b[36m0.3255\u001b[0m        \u001b[32m2.5417\u001b[0m       \u001b[35m0.3925\u001b[0m        \u001b[31m2.3853\u001b[0m     +  0.0010  1.3749\n",
      "     43       0.3150        \u001b[32m2.5379\u001b[0m       \u001b[35m0.3962\u001b[0m        \u001b[31m2.3643\u001b[0m     +  0.0010  1.3915\n",
      "     44       0.3160        \u001b[32m2.5312\u001b[0m       \u001b[35m0.3975\u001b[0m        2.3684        0.0009  1.3946\n",
      "     45       \u001b[36m0.3265\u001b[0m        \u001b[32m2.5091\u001b[0m       0.3875        \u001b[31m2.3583\u001b[0m     +  0.0009  1.3977\n",
      "     46       \u001b[36m0.3335\u001b[0m        2.5103       0.3962        \u001b[31m2.3379\u001b[0m     +  0.0009  1.4074\n",
      "     47       0.3285        \u001b[32m2.4937\u001b[0m       0.3975        \u001b[31m2.3310\u001b[0m     +  0.0009  1.3835\n",
      "     48       0.3267        2.4976       0.3950        2.3421        0.0009  1.3862\n",
      "     49       \u001b[36m0.3352\u001b[0m        \u001b[32m2.4718\u001b[0m       \u001b[35m0.4037\u001b[0m        \u001b[31m2.3092\u001b[0m     +  0.0009  1.4038\n",
      "     50       \u001b[36m0.3377\u001b[0m        \u001b[32m2.4717\u001b[0m       0.3925        2.3317        0.0009  1.3875\n",
      "     51       \u001b[36m0.3450\u001b[0m        \u001b[32m2.4460\u001b[0m       0.4012        \u001b[31m2.2985\u001b[0m     +  0.0009  1.3932\n",
      "     52       0.3350        2.4584       0.4037        2.2986        0.0009  1.4124\n",
      "     53       \u001b[36m0.3468\u001b[0m        \u001b[32m2.4350\u001b[0m       0.3987        \u001b[31m2.2874\u001b[0m     +  0.0009  1.3875\n",
      "     54       0.3460        \u001b[32m2.4152\u001b[0m       \u001b[35m0.4062\u001b[0m        \u001b[31m2.2831\u001b[0m     +  0.0009  1.3936\n",
      "     55       0.3420        2.4305       \u001b[35m0.4150\u001b[0m        \u001b[31m2.2753\u001b[0m     +  0.0009  1.4085\n",
      "     56       0.3370        2.4468       0.4075        2.2912        0.0009  1.4043\n",
      "     57       0.3458        2.4262       0.4088        \u001b[31m2.2726\u001b[0m     +  0.0009  1.4211\n",
      "     58       \u001b[36m0.3530\u001b[0m        \u001b[32m2.3890\u001b[0m       \u001b[35m0.4250\u001b[0m        \u001b[31m2.2661\u001b[0m     +  0.0009  1.4144\n",
      "     59       0.3478        2.3918       0.4075        2.2799        0.0009  1.4115\n",
      "     60       \u001b[36m0.3620\u001b[0m        \u001b[32m2.3862\u001b[0m       \u001b[35m0.4275\u001b[0m        \u001b[31m2.2228\u001b[0m     +  0.0009  1.4216\n",
      "     61       0.3545        2.3905       0.4275        2.2335        0.0009  1.4050\n",
      "     62       0.3588        \u001b[32m2.3816\u001b[0m       0.4163        2.2232        0.0009  1.4088\n",
      "     63       0.3515        \u001b[32m2.3700\u001b[0m       0.4150        2.2371        0.0009  1.4212\n",
      "     64       0.3540        2.3861       0.4263        \u001b[31m2.2107\u001b[0m     +  0.0009  1.4013\n",
      "     65       0.3568        2.3713       0.4100        \u001b[31m2.2104\u001b[0m     +  0.0009  1.4155\n",
      "     66       0.3525        2.3855       \u001b[35m0.4300\u001b[0m        \u001b[31m2.1903\u001b[0m     +  0.0009  1.4184\n",
      "     67       \u001b[36m0.3645\u001b[0m        \u001b[32m2.3588\u001b[0m       0.4163        2.2220        0.0009  1.4082\n",
      "     68       0.3610        \u001b[32m2.3465\u001b[0m       0.4050        2.2222        0.0009  1.4134\n",
      "     69       0.3585        2.3546       0.4225        2.1924        0.0009  1.4123\n",
      "     70       \u001b[36m0.3668\u001b[0m        \u001b[32m2.3356\u001b[0m       \u001b[35m0.4375\u001b[0m        \u001b[31m2.1895\u001b[0m     +  0.0009  1.4054\n",
      "     71       0.3600        2.3407       \u001b[35m0.4387\u001b[0m        \u001b[31m2.1697\u001b[0m     +  0.0009  1.4084\n",
      "     72       \u001b[36m0.3685\u001b[0m        \u001b[32m2.3306\u001b[0m       0.4325        2.1852        0.0009  1.4060\n",
      "     73       \u001b[36m0.3720\u001b[0m        2.3413       0.4275        2.1720        0.0009  1.3894\n",
      "     74       0.3720        \u001b[32m2.3037\u001b[0m       0.4313        2.1700        0.0009  1.4030\n",
      "     75       0.3710        2.3312       \u001b[35m0.4412\u001b[0m        \u001b[31m2.1658\u001b[0m     +  0.0009  1.4114\n",
      "     76       \u001b[36m0.3845\u001b[0m        \u001b[32m2.2981\u001b[0m       0.4288        2.1827        0.0009  1.4059\n",
      "     77       0.3670        2.3224       0.4387        \u001b[31m2.1561\u001b[0m     +  0.0008  1.4218\n",
      "     78       0.3815        \u001b[32m2.2906\u001b[0m       0.4313        2.1779        0.0008  1.3876\n",
      "     79       0.3812        2.2972       0.4350        2.1789        0.0008  1.3946\n",
      "     80       0.3683        2.3286       0.4400        \u001b[31m2.1486\u001b[0m     +  0.0008  1.4119\n",
      "     81       0.3713        2.3180       0.4375        2.1738        0.0008  1.3875\n",
      "     82       0.3755        2.3223       \u001b[35m0.4550\u001b[0m        \u001b[31m2.1391\u001b[0m     +  0.0008  1.4020\n",
      "     83       0.3683        2.3156       0.4387        2.1579        0.0008  1.4189\n",
      "     84       0.3638        2.3097       0.4537        \u001b[31m2.1366\u001b[0m     +  0.0008  1.3945\n",
      "     85       \u001b[36m0.3850\u001b[0m        2.2912       \u001b[35m0.4600\u001b[0m        \u001b[31m2.1219\u001b[0m     +  0.0008  1.4205\n",
      "     86       \u001b[36m0.3907\u001b[0m        \u001b[32m2.2660\u001b[0m       \u001b[35m0.4612\u001b[0m        \u001b[31m2.1205\u001b[0m     +  0.0008  1.4000\n",
      "     87       0.3815        2.2782       0.4487        2.1254        0.0008  1.3875\n",
      "     88       0.3847        2.2829       \u001b[35m0.4700\u001b[0m        \u001b[31m2.1097\u001b[0m     +  0.0008  1.4050\n",
      "     89       \u001b[36m0.3920\u001b[0m        \u001b[32m2.2597\u001b[0m       0.4650        \u001b[31m2.1064\u001b[0m     +  0.0008  1.4008\n",
      "     90       0.3887        2.2736       0.4562        2.1151        0.0008  1.3979\n",
      "     91       0.3847        2.2618       0.4587        \u001b[31m2.1028\u001b[0m     +  0.0008  1.4223\n",
      "     92       0.3842        2.2735       0.4575        \u001b[31m2.0988\u001b[0m     +  0.0008  1.4086\n",
      "     93       0.3785        2.2613       0.4587        2.1028        0.0008  1.4058\n",
      "     94       0.3830        2.2625       0.4462        2.1041        0.0008  1.4069\n",
      "     95       \u001b[36m0.3962\u001b[0m        \u001b[32m2.2339\u001b[0m       \u001b[35m0.4738\u001b[0m        \u001b[31m2.0821\u001b[0m     +  0.0008  1.3856\n",
      "     96       0.3867        2.2522       0.4625        2.0892        0.0008  1.3956\n",
      "     97       0.3940        2.2688       0.4600        2.1017        0.0008  1.3970\n",
      "     98       0.3930        2.2529       0.4650        2.0927        0.0008  1.3949\n",
      "     99       0.3917        2.2414       0.4612        2.0998        0.0008  1.3975\n",
      "    100       0.3937        \u001b[32m2.2260\u001b[0m       0.4512        2.1131        0.0008  1.3959\n",
      "    101       0.3900        2.2394       0.4675        2.0886        0.0007  1.3834\n",
      "    102       0.3930        2.2472       0.4625        2.0974        0.0007  1.4001\n",
      "    103       0.3832        2.2418       0.4587        2.0831        0.0007  1.4059\n",
      "    104       0.3880        2.2435       0.4675        \u001b[31m2.0751\u001b[0m     +  0.0007  1.4082\n",
      "    105       0.3907        2.2421       0.4650        \u001b[31m2.0744\u001b[0m     +  0.0007  1.4209\n",
      "    106       0.3887        2.2641       0.4587        2.0819        0.0007  1.3982\n",
      "    107       0.3857        2.2465       \u001b[35m0.4763\u001b[0m        \u001b[31m2.0619\u001b[0m     +  0.0007  1.3941\n",
      "    108       \u001b[36m0.4007\u001b[0m        \u001b[32m2.2089\u001b[0m       0.4675        \u001b[31m2.0563\u001b[0m     +  0.0007  1.4166\n",
      "    109       0.3800        2.2552       0.4537        2.0780        0.0007  1.3920\n",
      "    110       0.3940        2.2107       0.4738        \u001b[31m2.0540\u001b[0m     +  0.0007  1.3939\n",
      "    111       0.3897        2.2371       0.4662        2.0597        0.0007  1.4413\n",
      "    112       \u001b[36m0.4020\u001b[0m        2.2146       0.4662        2.0571        0.0007  1.3880\n",
      "    113       0.4000        2.2090       \u001b[35m0.4800\u001b[0m        \u001b[31m2.0432\u001b[0m     +  0.0007  1.3998\n",
      "    114       0.4005        \u001b[32m2.2061\u001b[0m       0.4738        2.0534        0.0007  1.4041\n",
      "    115       0.3965        \u001b[32m2.1888\u001b[0m       0.4763        2.0525        0.0007  1.3958\n",
      "    116       0.3915        2.2114       0.4662        \u001b[31m2.0371\u001b[0m     +  0.0007  1.4001\n",
      "    117       0.4020        2.2124       0.4562        2.0511        0.0007  1.4092\n",
      "    118       0.4005        2.2048       0.4700        2.0456        0.0007  1.4002\n",
      "    119       0.3950        2.2166       0.4688        \u001b[31m2.0288\u001b[0m     +  0.0007  1.4126\n",
      "    120       0.3945        2.2062       0.4788        2.0438        0.0007  1.4166\n",
      "    121       0.3867        2.2225       0.4763        2.0358        0.0007  1.4054\n",
      "    122       \u001b[36m0.4062\u001b[0m        2.2071       0.4688        2.0360        0.0006  1.4166\n",
      "    123       0.3960        2.2232       0.4637        2.0532        0.0006  1.4124\n",
      "    124       \u001b[36m0.4083\u001b[0m        \u001b[32m2.1815\u001b[0m       0.4775        2.0329        0.0006  1.4080\n",
      "    125       0.3962        2.2031       0.4775        2.0364        0.0006  1.4169\n",
      "    126       0.4010        2.1991       0.4775        \u001b[31m2.0276\u001b[0m     +  0.0006  1.4083\n",
      "    127       0.3967        2.2064       0.4713        2.0410        0.0006  1.4124\n",
      "    128       0.3980        2.1991       0.4662        2.0276        0.0006  1.4169\n",
      "    129       \u001b[36m0.4133\u001b[0m        \u001b[32m2.1806\u001b[0m       \u001b[35m0.4850\u001b[0m        \u001b[31m2.0095\u001b[0m     +  0.0006  1.4048\n",
      "    130       0.4007        2.1915       0.4738        2.0250        0.0006  1.4088\n",
      "    131       0.4012        2.2081       0.4850        2.0180        0.0006  1.4168\n",
      "    132       \u001b[36m0.4160\u001b[0m        \u001b[32m2.1677\u001b[0m       0.4850        \u001b[31m2.0082\u001b[0m     +  0.0006  1.4087\n",
      "    133       0.4115        2.1709       0.4838        2.0111        0.0006  1.4125\n",
      "    134       0.4115        2.1941       0.4788        2.0117        0.0006  1.4127\n",
      "    135       0.4158        \u001b[32m2.1560\u001b[0m       0.4750        2.0180        0.0006  1.4005\n",
      "    136       0.4103        2.1772       0.4800        2.0126        0.0006  1.4207\n",
      "    137       0.4070        2.1843       0.4675        2.0358        0.0006  1.4084\n",
      "    138       0.4030        2.1876       0.4788        2.0113        0.0006  1.4080\n",
      "    139       0.4078        2.1805       0.4788        2.0109        0.0006  1.4169\n",
      "    140       0.4083        2.1797       \u001b[35m0.4875\u001b[0m        \u001b[31m2.0058\u001b[0m     +  0.0006  1.4091\n",
      "    141       0.4050        2.1788       0.4788        2.0170        0.0005  1.4123\n",
      "    142       0.4105        2.1601       \u001b[35m0.4913\u001b[0m        \u001b[31m1.9980\u001b[0m     +  0.0005  1.4221\n",
      "    143       0.4025        2.1806       \u001b[35m0.4925\u001b[0m        \u001b[31m1.9851\u001b[0m     +  0.0005  1.4018\n",
      "    144       \u001b[36m0.4180\u001b[0m        2.1653       0.4700        2.0120        0.0005  1.4163\n",
      "    145       \u001b[36m0.4223\u001b[0m        2.1618       0.4775        2.0085        0.0005  1.4168\n",
      "    146       0.4130        2.1738       0.4700        2.0272        0.0005  1.4079\n",
      "    147       0.4203        2.1583       0.4700        2.0121        0.0005  1.4127\n",
      "    148       0.4027        2.1814       0.4788        2.0007        0.0005  1.4122\n",
      "    149       0.4060        \u001b[32m2.1391\u001b[0m       0.4800        1.9942        0.0005  1.4043\n",
      "    150       0.4173        2.1713       0.4875        \u001b[31m1.9846\u001b[0m     +  0.0005  1.4166\n",
      "    151       0.4113        2.1578       0.4650        2.0030        0.0005  1.4110\n",
      "    152       0.4075        2.1661       0.4850        1.9846        0.0005  1.4123\n",
      "    153       0.4100        \u001b[32m2.1364\u001b[0m       0.4788        1.9964        0.0005  1.4349\n",
      "    154       0.4135        2.1742       0.4775        1.9962        0.0005  1.3875\n",
      "    155       0.4085        2.1621       \u001b[35m0.4950\u001b[0m        1.9874        0.0005  1.4038\n",
      "    156       0.4183        2.1509       0.4825        1.9946        0.0005  1.4503\n",
      "    157       0.4163        2.1482       0.4838        \u001b[31m1.9835\u001b[0m     +  0.0005  1.3908\n",
      "    158       \u001b[36m0.4233\u001b[0m        2.1511       0.4925        \u001b[31m1.9796\u001b[0m     +  0.0005  1.3956\n",
      "    159       0.4115        2.1578       0.4938        \u001b[31m1.9766\u001b[0m     +  0.0005  1.4331\n",
      "    160       \u001b[36m0.4263\u001b[0m        \u001b[32m2.1281\u001b[0m       0.4900        \u001b[31m1.9735\u001b[0m     +  0.0005  1.4042\n",
      "    161       0.4073        2.1468       0.4950        \u001b[31m1.9690\u001b[0m     +  0.0004  1.3986\n",
      "    162       0.4090        2.1587       0.4875        1.9784        0.0004  1.3898\n",
      "    163       0.4218        2.1400       0.4938        1.9731        0.0004  1.3959\n",
      "    164       0.4128        2.1458       0.4788        1.9876        0.0004  1.4220\n",
      "    165       0.4150        2.1529       \u001b[35m0.4988\u001b[0m        \u001b[31m1.9616\u001b[0m     +  0.0004  1.4101\n",
      "    166       0.4173        2.1504       0.4913        1.9693        0.0004  1.4336\n",
      "    167       0.4200        2.1455       0.4938        1.9710        0.0004  1.4127\n",
      "    168       0.4208        \u001b[32m2.1202\u001b[0m       0.4950        1.9685        0.0004  1.4260\n",
      "    169       0.4193        2.1276       0.4913        1.9770        0.0004  1.4290\n",
      "    170       \u001b[36m0.4293\u001b[0m        2.1459       0.4875        1.9882        0.0004  1.4014\n",
      "    171       0.4160        2.1377       0.4888        1.9772        0.0004  1.4292\n",
      "    172       0.4178        2.1278       0.4863        1.9760        0.0004  1.4375\n",
      "    173       0.4115        2.1570       \u001b[35m0.5012\u001b[0m        \u001b[31m1.9592\u001b[0m     +  0.0004  1.4293\n",
      "    174       0.4125        2.1566       0.4963        1.9606        0.0004  1.4330\n",
      "    175       0.4128        2.1638       0.4863        1.9691        0.0004  1.4742\n",
      "    176       0.4288        2.1218       0.4888        1.9715        0.0004  1.4240\n",
      "    177       0.4208        \u001b[32m2.1189\u001b[0m       0.4913        1.9667        0.0004  1.4381\n",
      "    178       0.4200        2.1358       0.4975        1.9696        0.0004  1.4934\n",
      "    179       0.4190        2.1286       0.4900        1.9605        0.0004  1.5246\n",
      "    180       0.4178        2.1344       0.4988        \u001b[31m1.9528\u001b[0m     +  0.0003  1.6117\n",
      "    181       0.4225        \u001b[32m2.1174\u001b[0m       0.4925        1.9688        0.0003  1.4250\n",
      "    182       \u001b[36m0.4303\u001b[0m        \u001b[32m2.1132\u001b[0m       0.4913        1.9674        0.0003  1.4163\n",
      "    183       0.4180        2.1475       0.4925        1.9649        0.0003  1.4222\n",
      "    184       0.4110        2.1656       0.4988        \u001b[31m1.9477\u001b[0m     +  0.0003  1.4207\n",
      "    185       0.4085        2.1335       \u001b[35m0.5025\u001b[0m        1.9512        0.0003  1.4272\n",
      "    186       0.4255        2.1234       0.4863        1.9534        0.0003  1.4438\n",
      "    187       0.4218        2.1403       0.4863        1.9644        0.0003  1.3995\n",
      "    188       0.4173        2.1338       0.4863        1.9564        0.0003  1.4082\n",
      "    189       0.4163        2.1215       0.4988        \u001b[31m1.9433\u001b[0m     +  0.0003  1.4246\n",
      "    190       0.4170        2.1284       0.4913        1.9545        0.0003  1.4055\n",
      "    191       0.4193        2.1352       0.4900        1.9555        0.0003  1.4101\n",
      "    192       0.4155        2.1618       0.4925        1.9523        0.0003  1.4164\n",
      "    193       0.4223        2.1192       0.4875        1.9601        0.0003  1.3916\n",
      "    194       0.4240        2.1330       0.4863        1.9564        0.0003  1.4064\n",
      "    195       \u001b[36m0.4330\u001b[0m        \u001b[32m2.0966\u001b[0m       0.4938        1.9486        0.0003  1.4165\n",
      "    196       0.4300        2.1103       0.4988        1.9444        0.0003  1.3922\n",
      "    197       0.4210        2.1287       0.4888        1.9600        0.0003  1.4120\n",
      "    198       0.4210        2.1281       0.4838        1.9598        0.0003  1.4028\n",
      "    199       0.4230        2.1196       0.4888        1.9571        0.0003  1.4178\n",
      "    200       0.4143        2.1224       0.4863        1.9620        0.0003  1.4238\n",
      "    201       0.4140        2.1330       0.4913        1.9608        0.0002  1.4001\n",
      "    202       0.4303        2.1290       0.4925        1.9538        0.0002  1.4103\n",
      "    203       0.4330        2.1175       0.4888        1.9610        0.0002  1.4177\n",
      "    204       0.4168        2.1457       0.4900        1.9507        0.0002  1.3983\n",
      "    205       \u001b[36m0.4348\u001b[0m        \u001b[32m2.0954\u001b[0m       0.4950        1.9449        0.0002  1.4128\n",
      "    206       0.4255        2.1199       0.4888        1.9536        0.0002  1.4145\n",
      "    207       0.4165        2.1378       0.4875        1.9504        0.0002  1.4069\n",
      "    208       0.4210        2.1045       0.4838        1.9589        0.0002  1.4089\n",
      "    209       0.4180        2.1319       0.4850        1.9657        0.0002  1.4038\n",
      "    210       0.4285        2.1163       0.4925        1.9503        0.0002  1.3987\n",
      "    211       0.4193        2.1031       0.4913        1.9466        0.0002  1.4149\n",
      "    212       0.4223        2.1191       0.4900        \u001b[31m1.9400\u001b[0m     +  0.0002  1.4127\n",
      "    213       0.4168        2.1277       0.4913        1.9485        0.0002  1.3975\n",
      "    214       0.4178        2.1186       0.4925        1.9500        0.0002  1.4213\n",
      "    215       0.4260        2.1350       0.4900        1.9429        0.0002  1.4165\n",
      "    216       0.4260        2.1261       0.4938        \u001b[31m1.9382\u001b[0m     +  0.0002  1.4245\n",
      "    217       0.4253        2.1052       0.4925        1.9453        0.0002  1.4371\n",
      "    218       0.4308        \u001b[32m2.0911\u001b[0m       0.4963        1.9408        0.0002  1.3995\n",
      "    219       0.4163        2.1290       0.4913        1.9514        0.0002  1.4274\n",
      "    220       0.4245        \u001b[32m2.0898\u001b[0m       0.4888        1.9513        0.0002  1.4223\n",
      "    221       0.4153        2.1135       0.4925        \u001b[31m1.9357\u001b[0m     +  0.0002  1.3959\n",
      "    222       0.4283        2.1029       0.4888        1.9426        0.0002  1.4084\n",
      "    223       0.4235        2.1187       0.4888        1.9411        0.0002  1.4056\n",
      "    224       0.4215        2.1183       0.4875        1.9444        0.0002  1.4070\n",
      "    225       0.4230        2.1320       0.4913        1.9565        0.0001  1.4080\n",
      "    226       0.4185        2.1148       0.4938        1.9421        0.0001  1.4111\n",
      "    227       0.4218        2.1206       0.4925        1.9463        0.0001  1.4055\n",
      "    228       0.4193        2.1157       0.4938        1.9391        0.0001  1.4033\n",
      "    229       0.4240        2.1341       0.4900        1.9486        0.0001  1.4017\n",
      "    230       0.4235        2.0949       0.4888        1.9419        0.0001  1.4006\n",
      "    231       0.4285        2.1251       0.4888        1.9501        0.0001  1.4212\n",
      "    232       0.4280        2.1037       0.4963        1.9441        0.0001  1.3990\n",
      "    233       0.4290        \u001b[32m2.0857\u001b[0m       0.4900        1.9429        0.0001  1.4055\n",
      "    234       0.4263        2.0872       0.4963        1.9438        0.0001  1.4210\n",
      "    235       0.4065        2.1298       0.4900        1.9379        0.0001  1.4007\n",
      "    236       0.4235        2.1221       0.4900        1.9400        0.0001  1.4105\n",
      "    237       0.4288        2.1140       0.4900        1.9398        0.0001  1.4391\n",
      "    238       0.4170        2.1272       0.4913        1.9403        0.0001  1.4330\n",
      "    239       0.4258        2.1042       0.4925        1.9456        0.0001  1.4237\n",
      "    240       0.4218        2.1023       0.4925        1.9427        0.0001  1.4249\n",
      "    241       0.4173        2.1119       0.4975        \u001b[31m1.9339\u001b[0m     +  0.0001  1.4104\n",
      "    242       0.4300        2.1276       0.4913        1.9415        0.0001  1.4095\n",
      "    243       0.4243        2.1101       0.4863        1.9464        0.0001  1.4083\n",
      "    244       0.4148        2.1396       0.4900        1.9394        0.0001  1.4124\n",
      "    245       0.4265        2.0924       0.4950        1.9377        0.0001  1.4222\n",
      "    246       \u001b[36m0.4375\u001b[0m        \u001b[32m2.0710\u001b[0m       0.5000        \u001b[31m1.9297\u001b[0m     +  0.0001  1.4083\n",
      "    247       0.4255        2.0923       0.4900        1.9448        0.0001  1.4127\n",
      "    248       0.4268        2.1183       0.4850        1.9470        0.0001  1.4318\n",
      "    249       0.4280        2.1020       0.4950        1.9380        0.0001  1.4094\n",
      "    250       0.4238        2.1168       0.4925        1.9447        0.0001  1.4128\n",
      "    251       0.4215        2.1176       0.4975        1.9382        0.0001  1.4621\n",
      "    252       0.4123        2.1092       0.4988        1.9319        0.0001  1.4323\n",
      "    253       0.4238        2.0793       0.4875        1.9450        0.0001  1.4870\n",
      "    254       0.4275        2.1048       0.4900        1.9462        0.0001  1.4233\n",
      "    255       0.4283        2.0830       0.4913        1.9402        0.0001  1.4496\n",
      "    256       0.4280        2.1154       0.4863        1.9400        0.0001  1.4302\n",
      "    257       0.4343        2.0875       0.4913        1.9379        0.0001  1.4042\n",
      "    258       0.4195        2.1155       0.4875        1.9435        0.0000  1.4244\n",
      "    259       0.4283        2.0806       0.4900        1.9356        0.0000  1.4001\n",
      "    260       0.4235        2.1208       0.4900        1.9428        0.0000  1.4097\n",
      "    261       0.4335        2.0833       0.4875        1.9452        0.0000  1.4299\n",
      "    262       0.4280        2.0894       0.4888        1.9451        0.0000  1.4415\n",
      "    263       0.4228        2.1088       0.4863        1.9531        0.0000  1.4520\n",
      "    264       0.4225        2.1044       0.4900        1.9349        0.0000  1.4222\n",
      "    265       0.4313        2.0869       0.4875        1.9408        0.0000  1.4505\n",
      "    266       0.4155        2.1207       0.4888        1.9414        0.0000  1.4160\n",
      "    267       0.4218        2.1054       0.4875        1.9405        0.0000  1.4333\n",
      "    268       0.4213        2.1233       0.4888        1.9369        0.0000  1.4451\n",
      "    269       0.4163        2.1102       0.4875        1.9406        0.0000  1.4465\n",
      "    270       0.4178        2.1128       0.4888        1.9329        0.0000  1.4410\n",
      "    271       0.4235        2.1132       0.4900        1.9422        0.0000  1.4041\n",
      "    272       0.4255        2.1265       0.4863        1.9411        0.0000  1.3946\n",
      "    273       0.4208        2.1221       0.4913        1.9383        0.0000  1.3787\n",
      "    274       0.4173        2.1429       0.4913        1.9327        0.0000  1.3799\n",
      "    275       0.4295        2.1031       0.4975        1.9325        0.0000  1.4253\n",
      "    276       0.4280        2.1159       0.4950        1.9355        0.0000  1.4374\n",
      "    277       0.4225        2.1090       0.4913        1.9391        0.0000  1.4442\n",
      "    278       0.4248        2.1113       0.4963        1.9352        0.0000  1.4101\n",
      "    279       0.4288        2.0813       0.4925        \u001b[31m1.9287\u001b[0m     +  0.0000  1.3959\n",
      "    280       0.4355        2.0777       0.4900        1.9376        0.0000  1.4220\n",
      "    281       0.4190        2.1006       0.4975        \u001b[31m1.9280\u001b[0m     +  0.0000  1.4410\n",
      "    282       0.4313        2.1005       0.4938        1.9360        0.0000  1.4390\n",
      "    283       0.4228        2.1059       0.4900        1.9372        0.0000  1.4332\n",
      "    284       0.4300        2.0884       0.4900        1.9373        0.0000  1.4083\n",
      "    285       0.4293        2.1209       0.4963        1.9302        0.0000  1.4514\n",
      "    286       0.4218        2.0995       0.4900        1.9362        0.0000  1.4175\n",
      "    287       0.4368        2.0993       0.4925        1.9336        0.0000  1.3991\n",
      "    288       0.4218        2.1237       0.4975        1.9339        0.0000  1.3851\n",
      "    289       0.4368        2.0886       0.4913        1.9393        0.0000  1.4163\n",
      "    290       0.4288        2.1210       0.4913        1.9369        0.0000  1.4386\n",
      "    291       0.4245        2.0969       0.4913        1.9364        0.0000  1.4552\n",
      "    292       0.4248        2.1185       0.4913        1.9342        0.0000  1.4257\n",
      "    293       0.4278        2.1083       0.4913        1.9369        0.0000  1.4326\n",
      "    294       0.4258        2.0853       0.4913        1.9395        0.0000  1.4456\n",
      "    295       0.4295        2.0946       0.4938        1.9406        0.0000  1.4405\n",
      "    296       0.4273        2.1274       0.4950        1.9284        0.0000  1.4567\n",
      "    297       0.4230        2.0987       0.4950        1.9320        0.0000  1.3956\n",
      "    298       0.4160        2.1247       0.4938        1.9295        0.0000  1.4219\n",
      "    299       0.4205        2.1033       0.4938        1.9319        0.0000  1.4287\n",
      "    300       0.4318        2.0716       0.4950        1.9337        0.0000  1.4142\n",
      "预测频率： ['13.0', '9.0', '10.0', '13.0', '11.4', '13.0', '12.0', '15.0', '8.2', '13.2', '10.2', '11.2', '11.6', '13.2', '13.6', '13.8', '8.4', '9.4', '10.4', '11.4', '9.8', '12.8', '12.2', '12.2', '8.6', '9.6', '10.0', '11.6', '13.0', '13.0', '13.0', '15.6', '8.8', '9.8', '10.8', '11.8', '11.8', '13.8', '13.4', '14.4', '10.2', '9.0', '10.0', '10.0', '11.6', '12.6', '14.0', '13.6', '8.8', '12.6', '10.2', '10.8', '10.8', '12.8', '14.4', '14.8', '10.4', '9.4', '11.0', '11.4', '13.0', '13.4', '14.4', '13.2', '8.6', '9.6', '10.6', '12.2', '13.2', '13.6', '14.6', '13.2', '9.4', '9.8', '11.4', '11.8', '13.2', '13.8', '13.4', '15.0', '8.0', '9.0', '10.0', '10.4', '12.0', '13.0', '10.4', '15.0', '8.2', '9.2', '10.2', '10.6', '12.2', '13.2', '14.2', '14.8', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '13.8', '14.8', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.0', '8.8', '9.8', '10.8', '11.2', '12.8', '13.8', '14.8', '15.0', '8.0', '9.0', '10.0', '9.6', '12.0', '11.2', '9.2', '13.8', '9.0', '9.2', '10.0', '13.2', '12.0', '13.0', '13.6', '15.0', '8.0', '10.8', '10.2', '11.4', '12.4', '13.4', '13.8', '15.6', '8.6', '9.6', '10.6', '10.6', '13.0', '13.6', '14.6', '12.2', '8.8', '9.8', '10.8', '11.8', '13.2', '13.8', '14.8', '13.6', '10.6', '10.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '10.2', '9.6', '9.8', '12.2', '10.8', '13.2', '13.8', '14.4', '9.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.8', '10.6', '11.0', '11.2', '11.6', '12.6', '13.6', '14.6', '15.0', '9.8', '9.8', '11.0', '11.8', '12.8', '13.8', '14.8', '9.2', '10.6', '11.0', '10.0', '11.6', '12.0', '13.6', '13.6', '15.0', '9.8', '9.2', '10.2', '10.8', '12.2', '12.8', '14.2', '11.4', '8.8', '10.4', '10.4', '11.4', '12.4', '13.4', '13.4', '11.4', '9.6', '9.6', '10.6', '11.6', '13.2', '13.0', '14.6', '14.6', '8.8', '9.8', '10.8', '12.4', '12.8', '13.8', '14.8', '10.8', '12.2', '9.6', '13.2', '13.0', '12.0', '13.0', '13.0', '14.6', '11.4', '9.2', '11.2', '11.2', '13.2', '13.2', '13.6', '14.8', '12.4', '9.4', '10.4', '9.6', '12.4', '13.4', '14.4', '13.0', '12.8', '9.6', '10.6', '11.6', '12.6', '13.0', '14.6', '14.6', '8.8', '9.8', '10.8', '12.2', '12.8', '12.8', '12.4', '15.2', '8.2', '9.0', '10.0', '11.0', '11.6', '12.6', '14.0', '15.0', '8.8', '9.2', '10.2', '10.8', '11.8', '12.8', '14.2', '15.2', '12.2', '10.4', '10.4', '11.4', '12.4', '13.4', '14.0', '13.2', '8.6', '9.6', '10.6', '11.6', '12.8', '13.6', '14.6', '15.0', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '13.0', '10.0', '10.0', '11.4', '12.0', '10.2', '11.6', '13.4', '10.6', '14.4', '10.8', '10.2', '11.2', '12.2', '13.0', '14.0', '11.8', '9.4', '9.4', '10.4', '11.4', '12.4', '13.4', '12.2', '13.8', '13.0', '9.6', '10.6', '12.0', '12.6', '13.6', '13.0', '8.2', '8.8', '9.8', '10.8', '11.8', '13.2', '13.2', '13.0', '13.4', '9.6', '10.0', '10.0', '11.6', '12.0', '13.4', '14.0', '12.8', '9.2', '9.2', '9.8', '11.2', '12.2', '13.2', '14.8', '15.0', '9.6', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.4', '8.8', '9.8', '11.4', '11.8', '11.8', '13.2', '15.2', '14.4', '11.4', '13.0', '11.0', '12.0', '10.6', '13.0', '9.8', '13.0', '11.6', '8.8', '10.8', '10.2', '14.0', '13.2', '10.6', '14.8', '12.4', '9.4', '10.6', '10.2', '9.6', '11.4', '14.4', '14.4', '8.6', '9.6', '11.2', '11.6', '13.2', '11.6', '14.6', '14.2', '9.8', '9.8', '11.4', '11.8', '12.8', '13.8', '13.8', '9.2', '9.6', '13.4', '10.0', '10.6', '12.0', '13.0', '13.0', '10.2', '8.8', '12.2', '9.8', '11.2', '11.8', '13.8', '13.8', '12.4', '13.4', '11.4', '10.4', '11.4', '13.4', '14.0', '13.2', '15.4', '8.6', '9.6', '10.6', '12.2', '12.6', '13.6', '10.4', '15.2', '9.2', '9.8', '11.4', '11.8', '12.8', '12.8', '14.2', '15.8', '9.4', '9.0', '10.0', '8.4', '9.6', '13.0', '11.2', '14.6', '9.4', '9.8', '9.2', '11.2', '12.2', '9.0', '13.8', '14.8', '9.4', '9.4', '10.4', '10.4', '11.4', '9.8', '13.4', '14.4', '8.6', '9.6', '10.6', '10.0', '12.6', '13.6', '13.0', '14.6', '8.8', '9.8', '10.8', '14.0', '12.8', '12.8', '15.0', '15.8', '15.0', '9.6', '12.8', '11.0', '11.4', '13.0', '14.0', '13.0', '13.4', '9.8', '10.2', '10.6', '11.0', '13.2', '14.2', '14.0', '12.2', '10.4', '10.4', '10.8', '12.4', '13.4', '13.2', '14.8', '13.0', '12.2', '10.6', '11.6', '12.6', '13.6', '14.6', '15.0', '13.0', '9.8', '11.2', '11.8', '12.8', '13.8', '14.8', '9.6', '8.2', '14.4', '10.0', '10.0', '12.0', '13.6', '14.6', '10.6', '9.0', '9.2', '10.2', '11.2', '12.2', '13.2', '13.6', '15.2', '9.8', '9.4', '10.4', '11.4', '12.4', '13.4', '9.2', '9.6', '8.0', '9.6', '10.6', '12.2', '12.6', '10.0', '11.4', '14.6', '8.8', '9.8', '10.8', '13.2', '12.8', '13.8', '14.8', '15.8', '15.8', '10.4', '11.6', '11.0', '10.8', '11.4', '14.0', '14.4', '8.8', '9.2', '11.4', '11.8', '12.2', '12.6', '14.2', '10.4', '8.4', '12.0', '9.8', '11.4', '12.2', '13.4', '13.8', '13.2', '8.6', '9.6', '10.6', '11.6', '12.0', '10.6', '14.6', '15.6', '8.8', '9.8', '11.4', '11.8', '12.8', '13.8', '13.0', '15.6', '12.0', '9.6', '10.0', '11.4', '13.0', '13.4', '14.0', '15.0', '8.8', '9.2', '10.8', '11.8', '12.2', '13.2', '14.6', '15.2', '10.6', '9.4', '10.4', '11.4', '12.4', '13.4', '14.8', '14.8', '8.6', '9.6', '10.6', '11.6', '12.4', '14.0', '14.6', '15.4', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '14.4', '15.8', '11.0', '10.0', '11.0', '12.6', '13.0', '10.8', '14.2', '8.2', '9.2', '10.2', '11.2', '11.8', '13.2', '10.4', '12.0', '9.4', '9.4', '10.4', '11.4', '11.4', '13.4', '12.2', '8.0', '8.6', '9.6', '10.6', '11.6', '12.6', '11.4', '14.6', '15.0', '8.8', '9.8', '10.8', '11.8', '12.8', '10.4', '12.6', '15.0', '15.0', '14.4', '10.6', '10.6', '11.4', '14.0', '13.0', '9.6', '8.2', '13.6', '10.2', '11.2', '13.2', '11.8', '9.8', '12.4', '9.8', '9.4', '10.4', '11.4', '13.4', '9.6', '11.8', '14.0', '8.6', '9.6', '10.6', '12.2', '12.6', '14.0', '14.6', '13.6', '13.2', '10.2', '13.0', '11.8', '13.2', '12.2', '13.2', '10.4', '12.0', '9.0', '12.0', '12.0', '15.0', '13.0', '13.4', '15.0', '13.4', '9.2', '10.2', '11.2', '12.8', '13.2', '13.8', '14.8', '9.8', '9.4', '10.4', '12.8', '10.2', '13.4', '13.4', '15.8', '13.4', '9.6', '10.6', '11.6', '12.6', '13.0', '12.6', '15.0', '8.8', '9.8', '11.2', '14.6', '13.2', '13.8', '13.4', '15.8']\n",
      "真实频率： ['8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8', '8.0', '9.0', '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '8.2', '9.2', '10.2', '11.2', '12.2', '13.2', '14.2', '15.2', '8.4', '9.4', '10.4', '11.4', '12.4', '13.4', '14.4', '15.4', '8.6', '9.6', '10.6', '11.6', '12.6', '13.6', '14.6', '15.6', '8.8', '9.8', '10.8', '11.8', '12.8', '13.8', '14.8', '15.8']\n",
      "第2折准确率: 0.4975\n",
      "train_ind数量: 4000, validate_ind数量: 800, test_ind数量: 800\n",
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      lr     dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  ------  ------\n",
      "      1       \u001b[36m0.0240\u001b[0m        \u001b[32m3.7972\u001b[0m       \u001b[35m0.0350\u001b[0m        \u001b[31m3.6861\u001b[0m     +  0.0010  1.4404\n",
      "      2       \u001b[36m0.0283\u001b[0m        \u001b[32m3.7298\u001b[0m       \u001b[35m0.0413\u001b[0m        \u001b[31m3.6728\u001b[0m     +  0.0010  1.4192\n",
      "      3       \u001b[36m0.0352\u001b[0m        \u001b[32m3.6999\u001b[0m       \u001b[35m0.0712\u001b[0m        \u001b[31m3.6548\u001b[0m     +  0.0010  1.4214\n",
      "      4       \u001b[36m0.0387\u001b[0m        \u001b[32m3.6789\u001b[0m       \u001b[35m0.0900\u001b[0m        \u001b[31m3.6323\u001b[0m     +  0.0010  1.4427\n",
      "      5       \u001b[36m0.0542\u001b[0m        \u001b[32m3.6455\u001b[0m       \u001b[35m0.1100\u001b[0m        \u001b[31m3.6087\u001b[0m     +  0.0010  1.4000\n",
      "      6       \u001b[36m0.0685\u001b[0m        \u001b[32m3.6180\u001b[0m       \u001b[35m0.1200\u001b[0m        \u001b[31m3.5813\u001b[0m     +  0.0010  1.4064\n",
      "      7       \u001b[36m0.0800\u001b[0m        \u001b[32m3.5818\u001b[0m       \u001b[35m0.1450\u001b[0m        \u001b[31m3.5433\u001b[0m     +  0.0010  1.4445\n",
      "      8       \u001b[36m0.0978\u001b[0m        \u001b[32m3.5525\u001b[0m       \u001b[35m0.1675\u001b[0m        \u001b[31m3.4942\u001b[0m     +  0.0010  1.4321\n",
      "      9       \u001b[36m0.1160\u001b[0m        \u001b[32m3.5051\u001b[0m       \u001b[35m0.1900\u001b[0m        \u001b[31m3.4280\u001b[0m     +  0.0010  1.4458\n",
      "     10       \u001b[36m0.1283\u001b[0m        \u001b[32m3.4419\u001b[0m       \u001b[35m0.2075\u001b[0m        \u001b[31m3.3568\u001b[0m     +  0.0010  1.4627\n",
      "     11       \u001b[36m0.1535\u001b[0m        \u001b[32m3.3847\u001b[0m       \u001b[35m0.2112\u001b[0m        \u001b[31m3.2873\u001b[0m     +  0.0010  1.4461\n",
      "     12       \u001b[36m0.1675\u001b[0m        \u001b[32m3.3277\u001b[0m       \u001b[35m0.2288\u001b[0m        \u001b[31m3.2067\u001b[0m     +  0.0010  1.4392\n",
      "     13       \u001b[36m0.1913\u001b[0m        \u001b[32m3.2654\u001b[0m       \u001b[35m0.2450\u001b[0m        \u001b[31m3.1338\u001b[0m     +  0.0010  1.4582\n",
      "     14       \u001b[36m0.1950\u001b[0m        \u001b[32m3.2194\u001b[0m       \u001b[35m0.2562\u001b[0m        \u001b[31m3.0744\u001b[0m     +  0.0010  1.4238\n",
      "     15       \u001b[36m0.2042\u001b[0m        \u001b[32m3.1699\u001b[0m       \u001b[35m0.2612\u001b[0m        \u001b[31m3.0293\u001b[0m     +  0.0010  1.4672\n",
      "     16       \u001b[36m0.2140\u001b[0m        \u001b[32m3.1153\u001b[0m       \u001b[35m0.2637\u001b[0m        \u001b[31m2.9648\u001b[0m     +  0.0010  1.4360\n",
      "     17       \u001b[36m0.2145\u001b[0m        \u001b[32m3.0804\u001b[0m       \u001b[35m0.2737\u001b[0m        \u001b[31m2.9129\u001b[0m     +  0.0010  1.4319\n",
      "     18       \u001b[36m0.2235\u001b[0m        \u001b[32m3.0352\u001b[0m       \u001b[35m0.2762\u001b[0m        \u001b[31m2.8797\u001b[0m     +  0.0010  1.4323\n",
      "     19       \u001b[36m0.2305\u001b[0m        \u001b[32m3.0159\u001b[0m       \u001b[35m0.2888\u001b[0m        \u001b[31m2.8433\u001b[0m     +  0.0010  1.3913\n",
      "     20       \u001b[36m0.2395\u001b[0m        \u001b[32m2.9776\u001b[0m       \u001b[35m0.2975\u001b[0m        \u001b[31m2.8132\u001b[0m     +  0.0010  1.4227\n"
     ]
    }
   ],
   "source": [
    "#**************************************************\n",
    "# Benchmark数据集  EEGNET网络\n",
    "# !python3.8 Bench_freezing.py # Bench 1e-4学习率，S1~S20  F1=40,D=2,F2=80,Epsilon=20,shared_ratio=0.3,alpha=1.0\n",
    "# 所有折准确率: [0.68125, 0.6325, 0.6075, 0.6575, 0.655, 0.64375]\n",
    "# 平均准确率： 0.6462500000000001\n",
    "#**************************************************\n",
    "# 设置device（如果GPU可用则使用GPU，否则使用CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# 设置随机种子\n",
    "set_random_seeds(42)\n",
    "kfold = 6\n",
    "print(X_Bench.shape)  # (2160, 9, 1250)\n",
    "indices = generate_kfold_indices(meta_Bench, kfold=kfold)\n",
    "\n",
    "# 预训练阶段\n",
    "F1 = 25\n",
    "D = 2\n",
    "F2 = 50\n",
    "n_channels = X_Bench.shape[1] # 输入信号的通道数\n",
    "n_samples = X_Bench.shape[2] # 输入信号的采样点数，时长*采样率\n",
    "n_classes = 40\n",
    "time_kernel_length = 50\n",
    "shared_ratio = 0.5\n",
    "alpha = 0\n",
    "epsilon = 30\n",
    "\n",
    "Bench_save_path = \"Bench_eegnet_Sparse_dropout_1s_0_0.5_改.pth\"\n",
    "\n",
    "pre_accs = []\n",
    "best_test_acc = -1\n",
    "best_state_dict = None\n",
    "\n",
    "for k in range(kfold):\n",
    "    # 初始化模型\n",
    "    estimator = EEGNet_Sparse(F1,D,F2,n_channels,n_samples,n_classes,time_kernel_length,shared_ratio,alpha,epsilon)\n",
    "    estimator.set_params(optimizer__lr=1e-3,device=device) # optimizer__lr=3e-3,\n",
    "    train_ind, validate_ind, test_ind = match_kfold_indices(k, meta_Bench, indices)\n",
    "    # 合并train_ind和validate_ind作为新的训练集索引\n",
    "    new_train_ind = np.concatenate([train_ind, validate_ind])\n",
    "    new_valid_ind = test_ind  # 用test_ind作为验证集\n",
    "    new_test_ind = test_ind   # 用test_ind作为测试集\n",
    "\n",
    "    print(f\"train_ind数量: {len(new_train_ind)}, validate_ind数量: {len(new_valid_ind)}, test_ind数量: {len(new_test_ind)}\")\n",
    "    valid_ds = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_Bench[new_valid_ind], dtype=torch.float64),\n",
    "        torch.tensor(y_Bench[new_valid_ind], dtype=torch.long)\n",
    "    )\n",
    "    estimator.set_params(train_split=predefined_split(valid_ds))\n",
    "    estimator.fit(X_Bench[new_train_ind], y_Bench[new_train_ind])\n",
    "    # 测试集评估\n",
    "    p_labels = estimator.predict(X_Bench[new_test_ind])\n",
    "    p_freqs = [freq_map[label] for label in p_labels]\n",
    "    y_freqs = [freq_map[label] for label in y_Bench[new_test_ind]]\n",
    "    print(\"预测频率：\", p_freqs)\n",
    "    print(\"真实频率：\", y_freqs)\n",
    "    pre_accs.append(np.mean(p_labels == y_Bench[new_test_ind]))\n",
    "    print(f\"第{k+1}折准确率: {pre_accs[-1]}\")\n",
    "    # 保存最优模型\n",
    "    if pre_accs[-1] > best_test_acc:\n",
    "        best_test_acc = pre_accs[-1]\n",
    "        best_state_dict = copy.deepcopy(estimator.module.state_dict())\n",
    "print(f\"所有折准确率: {pre_accs}\")\n",
    "print(\"平均准确率：\", np.mean(pre_accs))\n",
    "# 保存测试集上最优的模型\n",
    "if best_state_dict is not None:\n",
    "    torch.save(best_state_dict, Bench_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "--------ssssss, /upload/yijun/S22.mat.7z\n",
      "--------ssssss, /upload/yijun/S24.mat.7z\n",
      "--------ssssss, /upload/yijun/S27.mat.7z\n",
      "--------ssssss, /upload/yijun/S28.mat.7z\n",
      "--------ssssss, /upload/yijun/S31.mat.7z\n",
      "--------ssssss, /upload/yijun/S34.mat.7z\n",
      "--------ssssss, /upload/yijun/S35.mat.7z\n",
      "subject 22 的准确率: 37.1%\n",
      "subject 24 的准确率: 38.3%\n",
      "subject 27 的准确率: 46.2%\n",
      "subject 28 的准确率: 32.5%\n",
      "subject 31 的准确率: 43.8%\n",
      "subject 34 的准确率: 35.4%\n",
      "subject 35 的准确率: 45.0%\n",
      "所有被试的准确率： {'22': 0.37083333333333335, '24': 0.38333333333333336, '27': 0.4625, '28': 0.325, '31': 0.4375, '34': 0.3541666666666667, '35': 0.45}\n",
      "所有被试的平均准确率: 39.8%\n",
      "所有被试准确率（无名称）: 37.1,38.3,46.2,32.5,43.8,35.4,45.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_subjects = [22,24,27,28,31,34,35] # 测试使用 \n",
    "pre_save_path = \"Bench_eegnet_Sparse_dropout_1s_0_0.5_改.pth\"\n",
    "# 加载预训练模型\n",
    "F1 = 8\n",
    "D = 2\n",
    "F2 = 16\n",
    "n_channels = X_Bench.shape[1] # 输入信号的通道数\n",
    "n_samples = X_Bench.shape[2] # 输入信号的采样点数，时长*采样率\n",
    "n_classes = 40\n",
    "time_kernel_length = 50\n",
    "shared_ratio = 0.5\n",
    "alpha = 0\n",
    "epsilon = 30\n",
    "estimator = EEGNet_Sparse(F1,D,F2,n_channels,n_samples,n_classes,time_kernel_length,shared_ratio,alpha,epsilon)\n",
    "estimator.set_params(device=device)\n",
    "estimator.initialize()  \n",
    "estimator.module.load_state_dict(torch.load(pre_save_path))\n",
    "subject_accs = {}\n",
    "\n",
    "# 逐一验证每个被试\n",
    "for test_subj in test_subjects:\n",
    "    # 获取该被试的数据\n",
    "    X, y, meta = Bench_paradigm.get_data(\n",
    "        Bench_dataset,\n",
    "        subjects=[test_subj],\n",
    "        return_concat=True,\n",
    "        n_jobs=None,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 直接用预训练模型预测\n",
    "    preds = estimator.predict(X)\n",
    "    acc = np.mean(preds == y)\n",
    "    subject_accs[str(test_subj)] = acc\n",
    "\n",
    "# 先把每个被试的准确率转成百分比并保留一位小数\n",
    "acc_list = [round(acc * 100, 1) for acc in subject_accs.values()]\n",
    "# 逐一打印单个被试\n",
    "for subj, acc in zip(test_subjects, acc_list):\n",
    "    print(f\"subject {subj} 的准确率: {acc:.1f}%\")\n",
    "\n",
    "# 打印所有被试准确率（字典仍是原始小数）\n",
    "print(\"所有被试的准确率：\", subject_accs)\n",
    "\n",
    "# 基于百分比后的数值再算平均\n",
    "mean_acc = np.mean(acc_list)\n",
    "print(f\"所有被试的平均准确率: {mean_acc:.1f}%\")\n",
    "\n",
    "# 额外一行：只显示所有被试准确率（百分数），逗号隔开\n",
    "print(\"所有被试准确率（无名称）:\", \",\".join([f\"{acc:.1f}\" for acc in acc_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metabci.brainda.algorithms.deep_learning import EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************************************************\n",
    "# Benchmark数据集  EEGNET网络\n",
    "# !python3.8 Bench_eegnet.py # Bench数据集 S1~S20 学习率1e-4，F1=40,D=2,F2=80\n",
    "# 所有折准确率: [0.5725, 0.6275, 0.58625, 0.57875, 0.57375, 0.59]\n",
    "# 平均准确率： 0.5881249999999999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "#**************************************************\n",
    "# 设置device（如果GPU可用则使用GPU，否则使用CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# 设置随机种子\n",
    "set_random_seeds(38)\n",
    "kfold = 6\n",
    "print(X_Bench.shape)  # (2160, 9, 1250)\n",
    "indices = generate_kfold_indices(meta_Bench, kfold=kfold)\n",
    "\n",
    "# 预训练阶段\n",
    "F1 = 25\n",
    "D = 2\n",
    "F2 = 50\n",
    "n_channels = X_Bench.shape[1] # 输入信号的通道数\n",
    "n_samples = X_Bench.shape[2] # 输入信号的采样点数，时长*采样率\n",
    "n_classes = 40\n",
    "time_kernel_length = 50\n",
    "\n",
    "Bench_save_path = \"Bench_eegnet_改.pth\"\n",
    "\n",
    "pre_accs = []\n",
    "best_test_acc = -1\n",
    "best_state_dict = None\n",
    "\n",
    "for k in range(kfold):\n",
    "    # 初始化模型\n",
    "    estimator = EEGNet(F1, D, F2, n_channels, n_samples, n_classes, time_kernel_length)\n",
    "    estimator.set_params(optimizer__lr=1e-4,device=device) # optimizer__lr=3e-3,\n",
    "    train_ind, validate_ind, test_ind = match_kfold_indices(k, meta_Bench, indices)\n",
    "    # 合并train_ind和validate_ind作为新的训练集索引\n",
    "    new_train_ind = np.concatenate([train_ind, validate_ind])\n",
    "    new_valid_ind = test_ind  # 用test_ind作为验证集\n",
    "    new_test_ind = test_ind   # 用test_ind作为测试集\n",
    "\n",
    "    print(f\"train_ind数量: {len(new_train_ind)}, validate_ind数量: {len(new_valid_ind)}, test_ind数量: {len(new_test_ind)}\")\n",
    "    valid_ds = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_Bench[new_valid_ind], dtype=torch.float64),\n",
    "        torch.tensor(y_Bench[new_valid_ind], dtype=torch.long)\n",
    "    )\n",
    "    estimator.set_params(train_split=predefined_split(valid_ds))\n",
    "    estimator.fit(X_Bench[new_train_ind], y_Bench[new_train_ind])\n",
    "    # 计算验证集准确率\n",
    "    val_preds = estimator.predict(X_Bench[new_valid_ind])\n",
    "    val_acc = np.mean(val_preds == y_Bench[new_valid_ind])\n",
    "    #print(\"当前折验证集准确率：\", val_acc)\n",
    "    # 测试集评估\n",
    "    p_labels = estimator.predict(X_Bench[new_test_ind])\n",
    "    p_freqs = [freq_map[label] for label in p_labels]\n",
    "    y_freqs = [freq_map[label] for label in y_Bench[new_test_ind]]\n",
    "    print(\"预测频率：\", p_freqs)\n",
    "    print(\"真实频率：\", y_freqs)\n",
    "    pre_accs.append(np.mean(p_labels == y_Bench[new_test_ind]))\n",
    "    print(f\"第{k+1}折准确率: {pre_accs[-1]}\")\n",
    "    # 保存最优模型\n",
    "    if pre_accs[-1] > best_test_acc:\n",
    "        best_test_acc = pre_accs[-1]\n",
    "        best_state_dict = copy.deepcopy(estimator.module.state_dict())\n",
    "print(f\"所有折准确率: {pre_accs}\")\n",
    "print(\"平均准确率：\", np.mean(pre_accs))\n",
    "# 保存测试集上最优的模型\n",
    "if best_state_dict is not None:\n",
    "    torch.save(best_state_dict, Bench_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "test_subjects = list(range(21, 36)) # 测试使用 \n",
    "pre_save_path = \"Bench_eegnet_改.pth\"\n",
    "# 加载预训练模型\n",
    "F1 = 25\n",
    "D = 2\n",
    "F2 = 50\n",
    "n_channels = X_Bench.shape[1] # 输入信号的通道数\n",
    "n_samples = X_Bench.shape[2] # 输入信号的采样点数，时长*采样率\n",
    "n_classes = 40\n",
    "time_kernel_length = 50\n",
    "estimator = EEGNet(F1, D, F2, n_channels, n_samples, n_classes, time_kernel_length)\n",
    "estimator.set_params(device=device)\n",
    "estimator.initialize()  \n",
    "estimator.module.load_state_dict(torch.load(pre_save_path))\n",
    "subject_accs = {}\n",
    "\n",
    "# 逐一验证每个被试\n",
    "for test_subj in test_subjects:\n",
    "    # 获取该被试的数据\n",
    "    X, y, meta = Bench_paradigm.get_data(\n",
    "        Bench_dataset,\n",
    "        subjects=[test_subj],\n",
    "        return_concat=True,\n",
    "        n_jobs=None,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 直接用预训练模型预测\n",
    "    preds = estimator.predict(X)\n",
    "    acc = np.mean(preds == y)\n",
    "    subject_accs[str(test_subj)] = acc\n",
    "    print(f\"subject {test_subj} 的准确率: {acc}\")\n",
    "\n",
    "# 统一打印所有被试的准确率\n",
    "print(\"所有被试的准确率：\", subject_accs)\n",
    "mean_acc = np.mean(list(subject_accs.values()))\n",
    "print(f\"所有被试的平均准确率: {mean_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metabci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
